\documentclass[hyperref,german,beleg,final,twoside]{cgvpub}
%weitere Optionen zum Ergänzen (in eckigen Klammern):
% 
% female	weibliche Titelbezeichnung bei Diplom
% bibnum	numerische Literaturschlüssel
% final 	für Abgabe	
% lof			Abbildungsverzeichis
% lot			Tabellenverzeichnis
% noproblem	keine Aufgabenstellung
% notoc			kein Inhaltsverzeichnis
% twoside		zweiseitig

\usepackage{tabularx}

\author{Josef Schulz}
\title{Ground-Truth-Renderer für Partikelbasierte Daten}
\birthday{20. Oktober 1989}
\placeofbirth{Dresden}
\matno{3658867}

\betreuer{Dipl-MedienInf. Joachim Staib}
\bibfiles{literatur.bib}
\problem{
Die Darstellung von Partikeldaten mittels Kugelglyphen ist in der wissenschaftlichen Visualisierung
inzwischen etabliert. Gerade bei dichten Datensätzen stellen kompakte Anordnungen von sehr vielen
Kugeln jedoch ein Problem für die Erkennbarkeit der zu visualisierenden Vorgänge dar. Eine Möglichkeit, diesem Problem zu begegnen ist es, über Blinn-Phong-Beleuchtung hinausgehende Effekte wie
globale Schatten oder den Einsatz von Methoden aus dem Volume-Rendering zu integrieren. Durch
deren Komplexität muss in Echtzeitvisualisierungen jedoch auf teilweise grobe Approximationen zu-
rückgegriffen werden. Die Einschätzung der Approximationsqualität fällt häufig schwer, da keine Visualisierung des exakten Verfahrens verfügbar ist.
Ziel dieser Belegarbeit ist die Umsetzung eines CPU-Renderers für Partikeldaten, der eine Reihe
von erweiterten Visualisierungseffekten unterstützt. Er soll die Grundlage für Ground-Truth-
Visualisierungen bieten.
Zunächst soll eine geeignete Softwarearchitektur konzipiert und umgesetzt werden. Die Partikel sollen als mit lichtemittierendem und ?absorbierendem Gas gefüllte Kugeln interpretiert werden. Es sollen anschließend Methoden entwickelt werden, um einen physikalisch plausiblen globalen Schattenwurf und Lichttransport für eine beliebige Anzahl an Punkt- und Richtungslichtquellen zu ermöglichen.
Die dafür notwendigen Gleichungen für Kugeln mit konstanter Dichte und Emission, sowie linearer
Absorption, sollen soweit wie möglich analytisch bestimmt und, sobald nicht mehr möglich, mittels
möglichst exakter numerischer Integratoren ausgewertet werden.

Die Teilaufgaben umfassen:

\begin{itemize}
\item Umfassende Literaturrecherche zur globalen Beleuchtungsrechnung in der Volumen Visualisierung
\item Schrittweise Konzeption und Umsetzung einer erweiterbaren Architektur zum Erzeugen von Ground-Truth-Bildern:

	\begin{enumerate}
		\item Zunächst als Raytracer für opake Kugeln, der globale Schatteneffekte von frei
		positionierbaren Punkt- und Richtungslichtquellen unterstützt
		\item Umsetzung eines Renderers, der Kugeln als Volumen nach dem Emissions-Absorptions-Modell rendert, dabei analytische Bestimmung des Volume-Rendering-Integrals, einschließlich Integration direkter Beleuchtung unverdeckter Lichtquellen
		\item Erweiterung zu verdeckten Lichtquellen und Bestimmung der Lichtstärke- und Farbe
		für Lichtstrahlen durch verdeckende Kugeln
	\end{enumerate}
\item Unterstützung für ein Standardformat wie VRML
\item Evaluation in Bezug auf Korrektheit, Bildartefakte und (numerische) Grenzfälle
\end{itemize}
\newpage
Optional:
\begin{itemize}
\item Unterstützung für Refraktionseffekte
\item Unterstützung komplexerer Materialtypen
\end{itemize}
}

\copyrighterklaerung{Hier soll jeder Autor die von ihm eingeholten
Zustimmungen der Copyright-Besitzer angeben bzw. die in Web Press
Rooms angegebenen generellen Konditionen seiner Text- und
Bild"ubernahmen zitieren.}

\acknowledgments{Die Danksagung...}
	
	 
\begin{document}

\chapter{Einleitung}

\section{Motivation}
	
	Partikel sind geometrische Objekte, welche in einem Raum durch ihre Position und beliebige weitere Attribute, wie einen Geschwindigkeitsvektor beschrieben werden können. Sie kommen bei computergestützten Simulationen zum Einsatz oder entstehen
	bei modernen Messvorgängen in Form von Punktwolken. Der Einsatz von Partikelsystemen ist weit verbreitet und die Visualisierung
	dieser ist eine der Kernkomponenten beim Analysieren und Verstehen der dargestellten Prozesse.
	Bei komplexen und dichten Szenen kommt es vor, dass innere Strukturen auf Grund von Verdeckungen nicht Sichtbar sind.
	Ein Ziel von Visualisierungen besteht in der Förderung der Menschlichen Wahrnehmung zur Erkennung von Beziehungen und Tendenzen
	der Abgebildeten Daten. 
	Eine Möglichkeit das Problem der verdeckten Objekten zu lösen, ist der Einsatz von Transparenz. Die Hinteren Objekte scheinen bis zum Betrachter durch. In Interaktiven Visualisierungen kann dem Benutzer die Möglichkeit geboten werden die Transparenz für Ausgewählte
	Regionen selbst zu variieren.
	Zusätzlich spielt der Einsatz von Licht eine wichtige Rolle, da der menschliche Wahrnehmungsapparat darauf trainiert ist Lichtwege zu
	rekonstruieren und anhand dieser Tiefeninformationen zu schätzen.
	Lokale Beleuchtungsmodelle erfüllen diese Aufgabe nicht, der Einsatz einer globalen Beleuchtung wird Notwendig.
	Auf Grund der hohen Komplexität der Algorithmen zur Berechnung der globalen Beleuchtung, müssen bei Echtzeitfähigen
	GPU-Implementierungen die Lösungen Approximiert werden.
	
	Ziel dieser Arbeit ist die Entwicklung eines CPU-Renderes dessen Fokus nicht auf Geschwindigkeit, sondern auf der Genauigkeit der
	Berechnung liegt. Die Partikel in Form von Kugeln werden mit Methoden des direkten Volumenrenderns abgebildet.
	Das Verfahren wird als direkt bezeichnet, da die Objekte nicht in polygonale Netze aufgelöst werden müssen um sie abzubilden.
	Die erzeugten Bilder, dienen als \textit{Ground-Truth} Information zur Evaluation von approximativen
	Implementierungen. Aufbauend auf der Volumen-Rendergleichung von Nelson Max aus der Arbeit \cite{Max:1995:OMD:614258.614298},
	soll dessen Emission- und Absorptionsmodell benutzt und eine Weitestgehend Analytische Lösung entwickelt werden.
	Zur Erzeugung der Bilder kommt ein \textit{Raycasting} Algorithmus zum Einsatz. 
	Das Verfahren ist nicht auf Kugeln beschränkt und lässt sich für implizite Oberflächen erweitern.
	Die erarbeitete Lösung stellt ebenfalls eine Approximation der eigentlichen dar. 
	Um die Berechnung zu beschleunigen kann die Genauigkeit der nummerischen Integration in Abhängigkeit der Stichprobengröße vereinfacht werden.
	Zusätzlich gibt es die Möglichkeit die Beleuchtungsberechnung der Verdeckten Objekte sukzessiv zu Vereinfachen, in Abhängigkeit
	einer einstellbaren Tiefe werden nur bis zu dieser die Partikel global beleuchtet. Alle weiteren verdeckten Kugeln werden
	durch eine weitere Vereinfachung der Rendergleichung gezeichnet.  
	
\section{Verwandte Arbeiten}

	Die Arbeit \cite{JSYR14} wurde verfasst, um den Leser einen Überblick über Techniken des
	renderns von Volumendaten in Echtzeit zu geben.
	Die in dieser Arbeit vorgestellten Algorithmen wurden mit Gütekriterien bewertet und klassifiziert.  
	Diese Kriterien sollen die Auswahl des Verfahrens für den Entwickler erleichtern.
	Alle vorgestellten Modelle sind Approximationen, sie generieren Optisch schöne Bilder, weichen jedoch weit von der Realität ab.
	
	Die Arbeit von Nelson Max \cite{Max:1995:OMD:614258.614298}, beschreibt die Grundlagen des Emission und Absorptionsmodells, welches Grundlage vieler Arbeiten im Bereich des Direkten Volumenrenderns bildet.
	Für die Rendergleichung entwickelt er in dieser Arbeit eine Allgemeine Lösung und beschreibt den Vorgang
	der Lichtstreuung im Detail. Am ende der Arbeit werden einige Lösungsvorschläge zur Implementierung vorgestellt.
	
	In der Publikation \cite{conf/pg/JungPP98} wird ein zum Teil Analytisches Verfahren vorgestellt.
	Der Algorithmus wurde zum Rendern von Voxelgittern konzipiert. 
	Jedem Voxel wird eine Dichte zu geordnet, aus welchem ein Wert für Transparenz abgeleitet wird.
	Hinter dem Voxelgitter befindet sich eine Lichtquelle und deren Lichtintensität wird durch das Volumen unterschiedlich Stark abgeschwächt.	Die Integrale der Gleichungen werden streckenweise Analytisch gelöst,
	wodurch ein Zuwachs an Genauigkeit erreicht wird. 

	\textit{Photon Mapping} ist ein Verfahren zum erzeugen von Globaler Beleuchtung. Es werden Photonen in die
	Szene geschossen, trifft ein Photon die Oberfläche, werden Informationen in der Photonenmap gespeichert.
	Wenn das Photon noch genügend Energie besitzt, wird in Abhängigkeit der Reflektionsrichtung ein weiterer
	Strahl verfolgt. Diese Vorgehensweise wiederholt sich das Photon seine Energie komplett an die Umgebung abgegeben hat, oder ein Abruchkriterium erfüllt wurde.
	In einem zweiten Schritt wird das Bild mit einem Raycast verfahren erzeugt.
	In der Arbeit \cite{JKRY12} wird die Photonenmap mit Histogrammen umgesetzt. Nach Parameteränderungen, werden
	nur die Betroffenen Histogramme ersetzt. Dadurch wird dieses Verfahren Echtzeitfähig.
	
	In der Arbeit \cite{journals/tvcg/AmentSW13} geht es um einen alternativen Ansatz, welcher nicht auf dem Emission und Absorptionsmodell aufbaut, sondern von einem Punkt Stahlen in die umliegende Nachbarschaft verfolgt um den
	Grad an Verdeckung an diesem Punkt zu bestimmen. Je mehr Segmente mit hoher Dichte in der Nachbarschaft liegen,
	umso geringer ist der Anteil des Lichtes, welches eben jenen Punkt erreicht. Ein Geschwindigkeitszuwachs wird durch eine Vor-integrierte Transferfunktion erreicht. Ein Vorteil dieses Verfahrens, stellt die Güte der erzeugten
	Schatten da.

	Eine weitere Arbeit aufbauend auf dem Prinzip der Ambienten Verdeckung stellt die Arbeit \cite{journals/tvcg/KnissPHSM03} vor.
	In dieser Arbeit hat Direktes und Indirektes Licht einen Einfluss auf das Ergebnis. 
	Mit Hilfe des so genannten \textit{blurring} werden die Farbanteile des Indirekten Lichtes in einem Buffer gehalten. Dieses verfahren approximiert die Streuungseffekte, welche in Materialien auftreten können.
	
	Eine Erweiterung dieses Verfahrens stellt die Arbeit \cite{10.1111:j.1467-8659.2009.01464.x} dar, welche hier nur der Vollständigkeit halber erwähnt werden soll.
	
\section{Aufbau der Arbeit}

	Die Arbeit ist folgendermaßen gegliedert. Zunächst werden im Grundlagen Kapitel die Technik des Raycastings erläutert und
	die grundlegenden Gleichungen für Kugel und Strahl und deren Schnitt behandelt. 
	Beendet wird das zweite Kapitel mit der Herleitung der Perspektivischen	Kamera anhand einer Lochkamera. 
	Im dritten Kapitel wird die Rendergleichung aufbauend auf der Arbeit von Nelson Max hergeleitet und eine Lösung
	dieser präsentiert werden.
	Das vierte Kapitel wird die sich mit der Implementierung des Algorithmus beschäftigen und im fünften Kapitel werden die
	Ergebnisse in Abhängigkeit der Parameter und der Rechenzeit evaluiert und anschließend im Fazit diskutiert werden.
	
\chapter{Grundlagen}

	Der Entwickelte Algorithmus basiert auf dem Verfahren des \textit{Raycasting}. Bei diesem Verfahren wird
	der Sensor der Kamera, welche am ende dieses Kapitels definiert wird, diskretisiert und für jeden Pixel
	wird mindestens ein Strahl in die Szene geschossen. 
	Für jeden Strahl muss eine Schnittberechnung mit den in der Szene befindlichen Objekten durchgeführt werden. 
	Wird ein Objekt vom Strahl geschnitten, muss die Rendergleichung für das dazugehörige Stahlsegment gelöst werden.
	
	In dieser Arbeit wird die Menge der Objekte auf Kugeln reduziert. Jede Kugel repräsentiert ein mit Gas gefüllten
	Partikel. Die Dichte im Inneren jedes Partikels wird als Konstant angenommen und die Menge der Transferfunktionen
	auf Lineare beschränkt werden. Im Folgenden werden die Gleichungen für Strahlen, Kugeln und deren Schnittberechnung
	definiert. Das Kapitel wird mit der Herleitung der perspektivischen Kamera beendet.
	
	Punkte werden in dieser Arbeit wie Vektoren behandelt, sie unterscheiden sich von diesen in den Formeln dadurch das sie
	Unterstrichen sind und keinen Pfeil besitzen wie ein Vektor. $\underline p$ stellt einen Punkt und $\vec{p}$ einen
	Vektor dar. Skalarprodukte werden mit Hilfe von spitzen Klammern $\langle \vec{a}, \vec{b} \rangle$ repräsentiert.

\section{Strahl und Kugelgleichung}

	Es wird mit der Definition des Strahls begonnen, der das Zentrale Element des Algorithmus bildet. Die Formel
	beschreibt wie jeder Punkt auf dem Strahl in Abhängigkeit eines skalaren Wertes $t$, eines Stützpunktes $\underline{o}$
	und einem Richtungsvektor $r$ bestimmt werden kann. Die Gleichung definiert sich wie folgt:
	
	\begin{equation}
	  	\underline{p}(t) = \underline{o} + t \cdot \vec{r} \text{, mit } t \in \mathbb{R}_+
	  	\label{eq:Strahl}
	\end{equation}
	
	Jeder Punkt auf dem Strahl $\underline{p}(t)$, ergibt sich aus der Addition eines Stützpunktes $\underline{o}$ mit dem durch $t$ skalierten Richtungsvektor $\vec{r}$. Der Vektor $\vec{r}$ muss normiert sein, die Länge des Vektors muss genau 1 betragen:
	$\left\|\left|\vec{r}\right|\right| = 1$.
	Ist der Wert von $t < 0$ liegt der Punkt hinter dem Ausgangspunkt des Strahls, andernfalls
	davor oder im Fall von $t = 0$ entspricht er eben diesen.
	
	Neben dem Strahl ist die Kugel, welche die Geometrische Form der betrachteten Partikel darstellt eine wichtige Rolle und soll
	ebenfalls definiert werden, damit die Schnittpunktberechnung durchgeführt werden kann.
	
	Die Fläche einer Kugel wird im $\mathbb{R}^3$ durch den Mittelpunkt $\underline{m} = (x_0, y_0, z_0)$ und den Radius $r$ parametrisiert. Jeder Punkt auf der Kugeloberfläche lässt sich durch den Abstand zum Mittelpunkt, dem Zentrum der Kugel definieren.
	Die Folgende Formel beschreibt diese Formulierung:
	
	\begin{equation}
		(x - x_0)^2 + (y - y_0)^2 + (z - z_0)^2 = r^2
		\label{eq:KugelR3}
	\end{equation}
	
	Jeder Punkt $\underline{p} = (x, y, z)$ der die Formel \ref{eq:KugelR3} erfüllt liegt auf der Oberfläche der Kugel.
	Die Kugelgleichung \ref{eq:KugelR3} lässt sich auf beliebige $\mathbb{R}^n\text{, mit } n \in \mathbb{N}_+$ erweitern,
	und die Beschreibung ist für alle $n$ äquivalent:
	
	\begin{equation}
		\langle\underline{p} - \underline{m}, \underline{p} - \underline{m}\rangle = r^2
		\label{eq:Kugel}
	\end{equation}

	Um den Schnittpunkt zwischen Kugel und Strahl zu berechnen wird die Kugelgleichung \ref{eq:Kugel} vereinfacht.
	Der Mittelpunkt der Kugel auf den Koordinaten Ursprung verschoben, liegen alle Punkte $p$ auf der Oberfläche $O$, wenn sie denn Abstand $r$ zum Koordinatenursprung haben. Die zu erfüllende Bedingung hat demnach folgende Form:
	
	\begin{equation}
		\vert\vert\underline{p}\vert\vert = r
		\label{eq:KugelEasy}
	\end{equation}
	
	Die Gleichung \ref{eq:KugelEasy} lässt sich Quartieren und der Strahl wird anschließend in diese eingesetzt. Das Resultat
	ist eine quadratische Gleichung. Bis auf das Skalar $t$ sind alle Werte bekannt. Die Gleichung
	
	\begin{equation}
			r^2 = \langle\underline{p}, \underline{p}\rangle = \langle r(t), r(t) \rangle = \langle \underline{p} + t \cdot \vec{r}, \underline{p} + t \cdot \vec{r} \rangle
			\label{eq:StrahlInKugel}
	\end{equation}
	
	kann nach $t$ umgestellt werden und die Nullstellen berechnet werden. Es gibt entweder keine, eine oder zwei Lösungen für die
	Gleichung. Werden die bestimmten Schnittpunkte in die Gleichung des Strahls eingesetzt können die Positionen der Schnittpositionen
	berechnet werden. Die Komplette Lösungsformel definiert sich im Folgenden:
	
	\begin{equation}
		t_{1,2} = \frac{-2 \cdot \langle \underline{p}, \vec{r} \rangle \pm \sqrt{4 \cdot \langle \underline{p}, \vec{r} \rangle^2 - 4 \cdot \langle \underline{p}, \underline{p} \rangle \cdot \langle \vec{r}, \vec{r} \rangle}}{2 \cdot \langle \vec{r}, \vec{r} \rangle}.
		\label{eq:Schnittpunkte}
	\end{equation}
	

\section{Die Perspektivische Kamera}

	Um in der realen Welt Bilder aufzunehmen wird eine Kamera benötigt, hier wird eine Simulation durchgeführt
	und für diese wird das Modell einer Kamera benötigt welches sich von der \textit{camera obscura} ableitet.
	Dabei handelt es sich um das Modell einer Lochkamera, diese besteht aus einem Kasten. Auf der einen Seite
	befindet sich ein Lichtempfindliches Material, welches den Sensor bildet und auf der an gegenüberliegenden
	Seite befindet sich ein schmales Loch. Das Licht wird von der Oberfläche der Abzubildenden Objekte reflektiert
	und fällt durch Loch auf den Sensor. Bei dem Vorgang der Abbildung findet eine Vertikale und Horizontale
	Spiegelung der Szene statt. Das bedeutet das Bild der Szene wird spiegelverkehrt aufgenommen.
	
	\begin{figure}[h]
		\centering
		\def\svgwidth{5cm}
		\input{images/cameraObscura.pdf_tex}
		\caption{Schematische Darstellung des Abbildungsvorgangs der \textit{camera obscura}}
		\label{fig:cameraObscura}
	\end{figure}
	
	Die Abbildung \ref{fig:cameraObscura} zeigt den Aufbau der \textit{Camera obscura} schematisch.
	Auf der Linken Seite der Abbildung befindet sich die Bildebene, auf welche die Szene abgebildet wird.
	In der Mitte der Abbildung \ref{fig:cameraObscura} befindet sich die Wand mit dem kleinen Loch.
	Hier wird die erste Abstraktion durchgeführt, denn in der Realität kann das Loch eine gewisse Größe nicht
	unterschreiten, da andernfalls kein Licht hindurch dringen würde. Aufgrund dieser minimalen Größe kommt
	es zu einer Glättung der Abbildung. Diese Einschränkung gilt für die Computersimulation nicht, es wird
	angenommen, dass das Loch unendlich klein ist, so dass die Szene unendlich genau Abgebildet werden kann.
	
	Auf der rechten Seite in der Abbildung \ref{fig:cameraObscura} befindet sich ein Objekt in Form einer Strecke,
	welche durch die Punkte $A$ und $B$ begrenzt wird. Der Punkt $B$ befindet sich mit der Sensormitte und dem
	Loch genau auf einer Ebene und er wird auf den Punkt $B'$ abgebildet. 
	Der zweite Punkt $A$ wird auf dem Punkt $A'$ abgebildet. Genauer zeigt die Abbildung \ref{fig:cameraObscura} den
	Strahlensatz der in diesem Zusammenhang gilt. 
		 
	Die Distanz zwischen dem Sensor und dem Loch der Kamera wird mit der Variable $f$ bezeichnet. Da es sich wie
	oben bereits erwähnt um eine Computersimulation handelt kann das Modell weiter abstrahiert werden.
	In der im Computer simulierten Welt kann der Sensor auch vor dem Loch positioniert werden, was zur Folge hat,
	das die Abbildung entspiegelt wird. 
	
	Die Position der Kamera soll im Folgenden mit der Variable $\underline{p}$ bezeichnet werden. Diese ist
	mit der Position des Lochs der Lochkamera identisch und wird in der Literatur auch als Augpunkt bezeichnet.
	Für jeden Pixel der Bildebene wird mindestens ein Strahl erzeugt, welcher als Stützpunkt die Position
	der Kamera erhält und der Richtungsvektor ist der Normierte Vektor von der Kamerapostion zum Pixel.
	Zur Vereinfachung wird angenommen, dass die Bildebene parallel zur xy-Ebene des Koordinatensystems der Szenen ist
	und der Augpunkt genau im Ursprung von diesem liegt.
	Die Fläche des Sensors wird in $W \cdot H$ Pixeln unterteilt.
	Für jeden Pixel $(x, y)$ wird ein Strahl $s$ in die Szene geschossen, dessen Stützpunkt der Augpunkt der Kamera
	ist und der Richtungsvektor der normierte Vektor $\vec{r}(x, y)$ welche sich ohne wie folgt definiert.
	
	\begin{equation}
		\vec{r}(x, y) = \left( 
							\begin{array}{l}
								(\frac{x}{W} \cdot 2 - 1) \cdot \frac{W}{H} \\
								\frac{y}{H} \cdot (- 2) + 1 \\
								f
							\end{array}							
					 	\right)
		\label{eq:direction}
	\end{equation}
	
	Es ist gilt zu beachten das der Richtungsvektor noch normiert werden muss: $\vec{r}(x, y) =  \frac{\vec{r}(x, y)}{\left|\left|\vec{r}(x, y)\right|\right|}$. 
	Jeder Kamera Strahl, im folgenden auch als Primärstrahl bezeichnet hat die folgende Form:
	
	\begin{equation}
		\underline{s} (x, y) = \underline{p} + t \cdot \vec{r}(x, y)
		\label{eq:primaryRay}
	\end{equation}
	
	Die Kamera kann an dieser Stelle nur entlang der z-Achse Blicken, eine Rotation im Raum lässt sich durch die Multiplikation
	einer Rotationsmatrix mit den Richtungsvektoren bewerkstelligen. Die Position des Kameramodells ist frei Wählbar, es genügt den
	Augpunkt zu verschieben. Mit Hilfe der Distanz $f$, der fokalen Länge kann ein Zoomeffekt der Kamera erzielt werden.
	
\chapter{Rendergleichung}

	In diesem Kapitel wird die Rendergleichung aufgestellt und die Grundlagen des Algorithmus hergeleitet,
	welcher beim Zeichnen der Kugeln zum Einsatz kommt.
	Zum Beginn wird das Emission und Absorptionsmodell aus der Arbeit von \cite{Max:1995:OMD:614258.614298}
	genauer betrachtet. Als Grundannahme wird die Menge der Transferfunktionen auf lineare Funktionen beschränkt,
	die Dichte soll im Volumen als konstant gelten. 
	Diese Arbeit befasst sich mit der Frage, ob sich mit diesen Einschränkungen das entstehende Volumenintegral analytisch lösen lässt.
	Gibt es eine analytische Lösung, lassen sich die Bilder effizient und sehr genau berechnen.
	Tritt der Fall ein, dass sich keine analytische Lösung für die Gleichung finden lässt, 
	werden die Integrale so weit es möglich analytisch gelöst und die restlichen Teile der Gleichung müssen 
	folglich Nummerisch approximiert werden.
	
\section{Das Optische Modell}

	Aufbauend auf dem Modell von Nelsen Max aus der Arbeit \cite{Max:1995:OMD:614258.614298} werden zur Herleitung Partikel in Form
	von Einheitskugeln betrachtet. Jede dieser Kugeln besitzt einen Radius $r$. Die Oberfläche eines Partikel $A$
	bestimmt sich durch das Produkt der Kreiszahl $\pi$ und dem Radius. So das gilt $A = \pi \cdot r$.
	Die Mittlere Dichte $\rho$ entspricht der Anzahl von Partikeln, welche sich in einem Einheitsvolumen befinden.
	Betrachtet wird im folgenden ein Zylinder, welcher mit der Kreisfläche $E$ und einer Länge $\Delta s$ parametrisiert wird. 
	Das Volumen eines solchen Zylinders entspricht $V_z = E \cdot \delta s$ und es enthält in etwa $N$ Partikel, mit $N = \rho E \delta s$.
	Die von dem Zylinder verdeckte Grundfläche $B$ entspricht bei einem sehr klein gewählten $\delta s$ in etwa $NA$, mit $NA = \rho AE \delta s$.
	Als Flussrichtung des Lichtes wird $\delta s$ gewählt. Der Anteil des Lichts, welcher mit Teilchen Wechselwirkt bis er $B$ erreicht beträgt $\rho A \delta s$. 
	Wenn $\delta s$ gegen Null geht, sinkt die Wahrscheinlichkeit, das sich Gaspartikel entlang der Lichtrichtung überlappen. Die Funktion $I(s)$ liefert die Intensität des Lichtes an der Distanz $s$. Wird die Lichtintensität
	$I(s)$ nach $s$ abgeleitet, ergibt sich die folgender Differenzialgleichung:
		 
	\begin{equation}
		\frac{dI}{ds} = -\rho(s)AI(s) = -\tau(s)I(s)
		\label{eq:MAX95grundDG}
	\end{equation}
	
	Auf der rechten Seite der Gleichung \ref{eq:MAX95LSGgrundDG} steht die Funktion $\tau(s)$, diese beschreibt
	die Abschwächung der Lichtintensität durch ein Volumen der Länge $s$. Wie in \ref{eq:MAX95EmissionDG} zusehen
	ist definiert sich der Abschwächungskoeffizient als das negative Produkt der mittleren Dichte $\rho$ mit der
	Oberfläche eines Partikels. Nelson Max hat die folgende Lösung für die Differenzialgleichung gefunden:
	
	\begin{equation}
		I(s) = I_0 \cdot e^{- \int\limits_{0}^{s} \tau(t) dt}
		\label{eq:MAX95LSGgrundDG}
	\end{equation}
	
	Der Parameter $I_0$ entspricht der Intensität an der Stelle $s = 0$, dabei handelt es sich um den Punkt,
	an dem der Lichtstrahl auf das Volumen trifft. Bei den zweiten Teil des Terms handelt es sich um die Transparenz
	des Mediums im Intervall $[0, s]$, welche durch $T(s) = exp(- \int_{0}^{l} \tau(t) dt)$ repräsentiert wird. 
	Nelson Max definiert neben der Transparenz einen Wert für den Grad an Verdeckung durch das Volumen $\alpha$, der in 
	der Englischen Literatur als \textit{opacity} bekannt ist.
	
	\begin{equation}
		\alpha = 1 - T(l) = 1 - e^{- \int\limits_{0}^{l} \tau(t) dt}
		\label{eq:MAX95Opacity}
	\end{equation}
	
	Ist die Funktion $\tau$ innerhalb des Volumens konstant, vereinfacht sich der Term für die Verdeckung zur Gleichung $\alpha = 1 - exp(-\tau l) = \tau l - (\tau l)^2 / 2 + \cdots$. 
	Im Rahmen dieser Arbeit ist der Begriff der Transferfunktion bereit mehr als einmal gefallen,
	eine solche Funktion bildet den Materialwert auf die optischen Eigenschaften der Gleichung ab.
	
\subsection{Emission}

	Wie in der Arbeit \cite{Max:1995:OMD:614258.614298} wird auch in dieser zuerst die Gleichung für die Emission
	hergeleitet. Neben der Abschwächung der Lichtintensität durch ein Volumen, kann zusätzlich an jedem Punkt in diesem Licht emittiert werden. In Worten bedeutete es, das ein Lichtstrahl welcher durch das Volumen geschossen
	wurde zusätzlich mit Licht angereichert wird. Zur Herleitung der Emission soll die Absorption zu nächst vernachlässigt werden. Betrachtet werden die Partikel aus dem vorhergehenden Abschnitt, jeder dieser Partikel
	wird im Folgenden als Transparent angenommen. Zusätzlich emittiert jeder von ihnen diffuses Licht. Das bedeutet
	jeder Partikel emittiert Licht, in alle Richtungen mit der gleichen Intensität $C$ über der projizierten Fläche $\rho A E \Delta s$. Dieser Effekt bewirkt eine Anreicherung des Lichtfluss $C \rho A E \Delta s$ welcher zur Basisfläche $E$ fließt.
	Durch diesen Zusammenhang ergibt sich eine weitere Differenzialgleichung:
	
	\begin{equation}
		\frac{dI}{ds} = C(s)\rho(s)A = C(s)\tau(s) = g(s)
		\label{eq:MAX95EmissionDG}
	\end{equation}
	
	Die Funktion $g(s)$ wird als Quellterm bezeichnet. Dieser Term beschreibt die Wechselwirkung des Lichtes mit dem
	Volumen über der Länge $s$. Zu der Differenzialgleichung \ref{eq:MAX95EmissionDG} hat Nelson Max ebenfalls eine
	Lösung gefunden welche sich wie folgt definiert:
	



\chapter{Implementation}

\chapter{Evaluation und Diskussion}
\section{Fazit}

%\chapter{title}
%
%\chapter{ein kapitel}
%\section{eine Grafik}
%\begin{figure}[htbp]
%	\centering
%		\includegraphics{test.png}
%	\caption{beschriftung}
%	\label{fig:diplominf}
%\end{figure}

\end{document}