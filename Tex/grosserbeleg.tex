\documentclass[hyperref,german,beleg,final,twoside]{cgvpub}
%weitere Optionen zum Ergänzen (in eckigen Klammern):
% 
% female	weibliche Titelbezeichnung bei Diplom
% bibnum	numerische Literaturschlüssel
% final 	für Abgabe	
% lof			Abbildungsverzeichis
% lot			Tabellenverzeichnis
% noproblem	keine Aufgabenstellung
% notoc			kein Inhaltsverzeichnis
% twoside		zweiseitig

\usepackage{tabularx}

\author{Josef Schulz}
\title{Ground-Truth-Renderer für Partikelbasierte Daten}
\birthday{20. Oktober 1989}
\placeofbirth{Dresden}
\matno{3658867}

\betreuer{Dipl-MedienInf. Joachim Staib}
\bibfiles{literatur.bib}
\problem{
Die Darstellung von Partikeldaten mittels Kugelglyphen ist in der wissenschaftlichen Visualisierung
inzwischen etabliert. Gerade bei dichten Datensätzen stellen kompakte Anordnungen von sehr vielen
Kugeln jedoch ein Problem für die Erkennbarkeit der zu visualisierenden Vorgänge dar. Eine Möglichkeit, diesem Problem zu begegnen ist es, über Blinn-Phong-Beleuchtung hinausgehende Effekte wie
globale Schatten oder den Einsatz von Methoden aus dem Volume-Rendering zu integrieren. Durch
deren Komplexität muss in Echtzeitvisualisierungen jedoch auf teilweise grobe Approximationen zu-
rückgegriffen werden. Die Einschätzung der Approximationsqualität fällt häufig schwer, da keine Visualisierung des exakten Verfahrens verfügbar ist.
Ziel dieser Belegarbeit ist die Umsetzung eines CPU-Renderers für Partikeldaten, der eine Reihe
von erweiterten Visualisierungseffekten unterstützt. Er soll die Grundlage für Ground-Truth-
Visualisierungen bieten.
Zunächst soll eine geeignete Softwarearchitektur konzipiert und umgesetzt werden. Die Partikel sollen als mit lichtemittierendem und ?absorbierendem Gas gefüllte Kugeln interpretiert werden. Es sollen anschließend Methoden entwickelt werden, um einen physikalisch plausiblen globalen Schattenwurf und Lichttransport für eine beliebige Anzahl an Punkt- und Richtungslichtquellen zu ermöglichen.
Die dafür notwendigen Gleichungen für Kugeln mit konstanter Dichte und Emission, sowie linearer
Absorption, sollen soweit wie möglich analytisch bestimmt und, sobald nicht mehr möglich, mittels
möglichst exakter numerischer Integratoren ausgewertet werden.

Die Teilaufgaben umfassen:

\begin{itemize}
\item Umfassende Literaturrecherche zur globalen Beleuchtungsrechnung in der Volumen Visualisierung
\item Schrittweise Konzeption und Umsetzung einer erweiterbaren Architektur zum Erzeugen von Ground-Truth-Bildern:

	\begin{enumerate}
		\item Zunächst als Raytracer für opake Kugeln, der globale Schatteneffekte von frei
		positionierbaren Punkt- und Richtungslichtquellen unterstützt
		\item Umsetzung eines Renderers, der Kugeln als Volumen nach dem Emissions-Absorptions-Modell rendert, dabei analytische Bestimmung des Volume-Rendering-Integrals, einschließlich Integration direkter Beleuchtung unverdeckter Lichtquellen
		\item Erweiterung zu verdeckten Lichtquellen und Bestimmung der Lichtstärke- und Farbe
		für Lichtstrahlen durch verdeckende Kugeln
	\end{enumerate}
\item Unterstützung für ein Standardformat wie VRML
\item Evaluation in Bezug auf Korrektheit, Bildartefakte und (numerische) Grenzfälle
\end{itemize}
\newpage
Optional:
\begin{itemize}
\item Unterstützung für Refraktionseffekte
\item Unterstützung komplexerer Materialtypen
\end{itemize}
}
\copyrighterklaerung{Hier soll jeder Autor die von ihm eingeholten
Zustimmungen der Copyright-Besitzer angeben bzw. die in Web Press
Rooms angegebenen generellen Konditionen seiner Text- und
Bild"ubernahmen zitieren.}
\acknowledgments{Die Danksagung...}

\begin{document}

\chapter{Einleitung}

	Ein Photon das im inneren der Sonne emittiert wird, ist dem kurzwelligen Spektrum der elektromagnetischen Wellen zugeordnet. Es handelt sich um Gammastrahlung. 
	Auf seiner langen Reise vom Kern bis zur Korona, 
	die rund 150.000 Jahre dauert, wird das Photon durch das enorm dichte und
	heiße Gas der Sonne blau verschoben.
	Auf den rund 690.000 km, die das Photon durch die Sonne wandert, absorbiert die Sonne
	einen großen Teil der Energie des Photons. Nachdem es die Sonne verlassen hat, benötigt
	das Photon weitere 8 Minuten um unsere Erde zu erreichen. 
	Die Geschichte von der Langen Reise dieses einzelnen Photons ist ein extremes Beispiel
	für den Vorgang der im Folgenden betrachtet wird.
	
	Licht ist im Physikalischen Sinn ein noch nicht gänzlich erfasstes Phänomen.
	Es zeigen sich Charakteristika von Wellen und von Teilchen, es wird vom
	Welle-Teilechodualismus gesprochen. Dieses wunderbare Modell ist ein Deckmantel
	für viele Fragen, die sich im Zusammenhang mit der Ausbreitung des Lichtes in unserer
	Welt ergeben und noch nicht alle beantwortet sind.
	
	Die Optik ist in der Physik die Lehre des Lichtes, sie beschreibt die Ausbreitung des Lichts
	und die Wechselwirkung mit Materie. In der Optik gibt es verschiedene Modelle, welche die
	Eigenschaften des Lichtes beschreiben.
	
	Die Strahlenoptik betrachtet das Licht in Form von Strahlen. Diese Modell approximiert 
	das Licht als Strahl, der von der Lichtquelle aus in die Welt geschossen wird.
	Diese Vereinfachung kann genutzt werde, wenn die Größenordnungen der Objekte, welche im
	Zusammenhang mit Licht betrachtet werden, deutlich über der Wellenlänge des Lichts liegt.
	Ist dies erfüllt können Typische Welleneigenschaften, wie Beugung und daraus resultierende
	Interferenz vernachlässigt werden.
	Für die Berechnung von Schatten, Reflexion und Brechung eignet sich die Strahlenoptik
	ausgesprochen gut und soll für diese Arbeit Grundlage der Betrachtung sein.
	Die Lichtstrahlen breiten sich immer nur geradlinig aus, bis sie auf einen Körper treffen und
	reflektiert, gestreut oder gebrochen werden. Sie können einander durchdringen ohne sich gegenseitig zu beeinflussen. 
	Der Weg des Lichtes lässt sich umkehren, was zur folge hat,
	dass die Gesetzt auch bei umgekehrter Lichtrichtung gelten.
	Dieses Prinzip ist essentiell für die Implementierung welche im Folgenden betrachtet wird,
	da die Strahlen von der Kamera aus in die Welt geschossen werden.
	
	Die Beleuchtung einer Computergenerierten Szene wird in vielen Implementierungen, die
	aus Computerspielen und anderen Visualisierungen bekannt sind stark vereinfacht.
	Diese Modelle lassen die Landschaften in einem schönen Licht erscheinen, vernachlässigen
	jedoch Physikalische Gesetzmäßigkeiten, wie die Erhaltung von Energie.
	Die Berechnung von Schatten welche sich durch den Weg des Lichtes ergeben sollten,
	werden oftmals nur sehr vereinfacht berechnet, insofern sie vorhanden sind.
	
	Für die meisten Anwendungen sind diese Approximationen vollkommen ausreichend.
	In der Computergrafik hat sich die Repräsentation von Daten mithilfe von Kugelglyphen
	bewährt. Als Beispiel soll das Modell eines Moleküls dienen.
	Ein Problem welches sich aus der Projektion auf den Bildschirm ergibt, ist die 
	Tiefenwahrnehmung des Menschen. Die durch den Computergenerierten Bilder sind in der Regel
	zweidimensionale Projektionen von dreidimensionalen Szenen. Der Mensch benötigt zur Erkennung
	von Lagenbeziehungen der Objekte in der Szene weitere Informationen.
	Im Laufe des Lebens lernt ein Mensch, die Merkmale des Lichtes zu Interpretieren.
	Auf diese Weise gelingt es einem Betrachter, die Lage der Lichtquelle nur aus einer Objekt
	Silhouette zu schätzen.
	Um diese Fähigkeit nutzen zu können wird jedoch eine komplexe Beleuchtung der Szene nötig.
	
\section{neue einleitung}
 
	Ein Problem der Echtzeitgrafik besteht in der Komplexität des Lichtes, welches auf Grund mangelnder
	Rechenkapazitäten oft nur lokal approximiert werden kann. In der Realität entstehen Schatten durch die Wechselwirkung des Lichtes mit der Umwelt.
	Anders in den meisten Computergenerierten Szenen, hier werden die Schatten mit Hilfe von rechenintensiver Verfahren oft sehr vereinfacht, insofern sie vorhanden sind.
	Es existieren allerdings einige algorithmische Verfahren, welche die Wechselwirkung von Photonen mit Oberflächen 
	physikalisch plausibel nachempfinden können. 
	Zu diesen zählen einfache Raytracer, bis hin zum Bidirektionalen Pathtracer oder dem so genannten Photonenmapping.
	Die Besonderheit dieser Algorithmen besteht darin, dass das Licht auf Strahlen durch die Szene verfolgt wird.
	Schatten, harte und weiche entstehen auf natürliche Weise. Trifft das Licht auf ein Objekt, wird es reflektiert
	oder absorbiert, das Licht ändert seinen Weg und seine Intensität und hinter dem Objekt entsteht ein Schatten.
	
	In der Realität bestehen viele Objekte aus Licht durchlässigen Materialien, wie Wachs, Glas oder Luft.
	Die bereits genannten physikalisch basierten Renderer kommen dabei an ihre Grenzen.
	Die Anzahl an möglichen Wechselwirkungen in einem Volumen ist weit größer, als bei Licht undurchlässigen Oberflächen. Die Komplexität der Berechnung steigt drastisch an.
	
	Datensätze aus der Medizin, der Biologie oder der Meteorologie enthalten oft mehr als die Oberflächenbeschreibung.
	Es handelt sich um so genannte Volumendaten, ein oft Dreidimensionales Array von skalaren Werten.
	Möglichkeiten der Visualisierung dieser Daten gibt es viele, in dieser Arbeit werden die Daten als
	Dichten von Gaskugeln interpretiert, welche anschließend durch Punkt und Richtungslichtquellen beleuchtet
	werden.
	
\chapter{Verwandte Arbeiten}

\section{A Survey of Volumetric Illumination Techniques for Interactive Volume Rendering}

	Die Arbeit \cite{JSYR14} fokussiert sich nicht auf ein spezielles Verfahren, vielmehr gibt sie einen Überblick über gängige Methoden zum rendern von Volumendaten. In der Einleitung der Arbeit wird auf die Unzulänglichkeiten
	verwiesen, die Methoden wie das Emission und Absorptionsmodell aufweisen, dieses im speziellen ist nur in der
	Lage Lokale Beleuchtungseffekte zu simulieren. Als Unterscheidungskriterien dienen das Volumetrische Modell,
	die Unabhängigkeit bezüglich der verwendeten Transferfunktion und die Möglichkeit den Algorithmus zu parallelisieren. Das Volumetrischen Modell trägt entschieden zur Komplexität und Geschwindigkeit bei,
	Voxel können als Boxen, Kugeln oder anderen Beliebigen Formen entsprechen. Die Transferfunktion als solche,
	ist in einigen Modellen fest vorgeschrieben, während sie in anderen Algorithmen zur Laufzeit ausgetauscht werden kann.
	
	Trotz der einleitend genannten Einschränkungen bleibt das Emission und Absorptionsmodell die Grundlage für
	die meisten Betrachtungen. Algorithmen, welche Daten vor dem eigentlichen Rendervorgang generieren, werden
	von jenen differenziert, welche die nötigen Daten zur Laufzeit generieren und somit weit weniger Speicher benötigen. Der anfallende Speicherbedarf verhindert bei einigen Algorithmen den Einsatz für große Datenmengen.

\section{Optical Models for Direct Volume Rendering}

	Die Arbeit von Nelson Max \cite{Max:1995:OMD:614258.614298}, beschreibt die Grundlagen des Emission und Absorptionsmodells, wie oben bereits erwähnt. 
	Nelson Max baut in seiner Arbeit eine Rendergleichung auf, welche sich zu Beginn auf
	das Emissionsmodell beschränkt. Anhand des Emissionsmodells werden die Grundlagen des Lichttransportes
	betrachtet und definiert. Erweitert wird die entstandene Gleichung mit einen Term zur Lichtabsorption,
	Streuung und Schattenberechnung. 
	Am ende seiner Arbeit geht er auf die Erweiterung durch die Vielfache Streuung ein und stellt einige Lösungsansätze vor.
	
	Es wird angeführt, dass sich die Gleichung in einigen Fällen wohl analytisch lösen ließe, im Allgemeinen
	wird zur Lösung der Rendergleichung auf Nummerische Integration verwiesen.
	
\section{An Analytical Ray Casting of Volume Data}

	Eine weitere sehr interessante Arbeit zum Thema Volumenintegral ist \cite{conf/pg/JungPP98}.
	Grundlage dieser Arbeit ist ein Reguläres Gitter, welches die Voxel repräsentiert. Jedem
	Voxel ist eine Dichte zugeordnet, welche die einzigen Materialparameter in der Gleichung sind.
	Als Algorithmus zum Zeichnen des Bildet dient ein \textit{Ray-Cast} Verfahren, welches entlang
	eines Sichtstrahls, an bestimmten Stützpunkten die Transparenz mit einander verrechnet.
	Diese Transparenten werden über eine Transferfunktion aus der Dichte eines Voxels erzeugt.
	Verwendet wird eine Lineare Transferfunktion, diese hat den Vorteil, das sich das Volumenintegral
	für den Durchlauf eines Voxels analytisch lösen lässt.
	
\section{Historygrams: Enabling Interactive Global Illumination in Direct Volume Rendering using Photon Mapping}

	\textit{Photon Mapping} ist ein Verfahren zum erzeugen von Globaler Beleuchtung. Im Prinzip eignet sich
	das Verfahren nicht zum Rendern in Echtzeit. In der Arbeit \cite{JKRY12} wir jedoch ein Ansatz vorgestellt,
	mit welchem sich das Photonmapping zum Bleuchten von Volumen in Echtzeit nutzen lässt und somit Physikalisch
	korrekte Beleuchtungen ermöglicht. Echtzeitfähigkeit erreicht der Ansatz dadurch, dass die für den Algorithmus
	notwendige Photonenmap nicht bei jedem Renderdurchlauf neu berechnet werden muss, sondern nur die Teile,
	welche nach einer Parameteränderung auch wirklich neu berechnet werden müssen aktualisiert werden. Um diese
	Änderung zu finden, kommen Histogramme zum Einsatz. Bei diesen Ansatz ist es Möglich die Transferfunktion zur Laufzeit zu ändern. Die Performance dieses Ansatz ist Hauptsächlich abhängig von der Anzahl der Photonen,
	welche durch die Szene verfolgt werden, der Anzahl an Lichtstahlsegmenten und der maximalen Anzahl von Streuungen.
	
\section{Ambient Volume Scattering}

	In der Arbeit \cite{journals/tvcg/AmentSW13} geht es um einen alternativen Ansatz, welcher nicht auf dem Emission und Absorptionsmodell aufbaut, sondern von einem Punkt Stahlen in die umliegende Nachbarschaft verfolgt um den
	Grad an Verdeckung an diesem Punkt zu bestimmen. Je mehr Segmente mit hoher Dichte in der Nachbarschaft liegen,
	umso geringer ist der Anteil des Lichtes, welches eben jenen Punkt erreicht. Ein Geschwindigkeitszuwachs wird durch eine Vor-integrierte Transferfunktion erreicht. Ein Vorteil dieses Verfahrens, stellt die Güte der erzeugten
	Schatten da.
	
\section{A Model Volume Lighting and Modeling}

	Eine weitere Arbeit aufbauend auf dem Prinzip der Ambienten Verdeckung stellt die Arbeit \cite{journals/tvcg/KnissPHSM03} vor.
	In dieser Arbeit hat Direktes und Indirektes Licht einen Einfluss auf das Ergebnis. 
	Mit Hilfe des so genannten \textit{blurring} werden die Farbanteile des Indirekten Lichtes in einem Buffer gehalten. Dieses verfahren approximiert die Streuungseffekte, welche in Materialien auftreten können.
	
	Eine Erweiterung dieses Verfahrens stellt die Arbeit \cite{10.1111:j.1467-8659.2009.01464.x} dar, welche hier nur der Vollständigkeit halber erwähnt werden soll.
	
\chapter{Grundlagen}

	In diesem Kapitel soll die verwendete Rendertechnik Begrifflich genauer abgegrenzt werden.
	Im Folgenden werden alle benötigten Mathematischen Formeln hergeleitet und erklärt.
	Am ende dieses Kapitels wird der Aufbau der Perspektivischen Kamera, 
	welche hier zum Einsatz kommt genau erläutert. 

\section{Verwendete Formelzeichen}

   \begin{table}[htbp]
     \centering
		\begin{tabularx}{\textwidth}{l|X}
  			\textbf{Formelzeichen} & \textbf{Erläuterung}  \\
  			\hline
  			$\mathbb{R}_+$						& Bezeichnet die Menge der Reellen Zahlen im Intervall $[0, \infty)$ \\
  			$\mathbb{N}_+$						& Bezeichnet die Menge der Natürlichen Zahlen im Intervall $[0, \infty)$ \\
  			$\underline{p}$ 					& Punkt im Raum  \\
  			$\vec{v}$							& Vektor im Raum \\
  			$\langle\vec{a}, \vec{b}\rangle$ 	& Skalarprodukt der Vektoren $\vec{a}$ und $\vec{b}$ \\
 		\end{tabularx}
 		\caption{Verwendete Formelzeichen}
      	\label{tbl:Formelzeichen}
      	% Verweis im Text mittels \ref{tbl:beispieltabelle}
    \end{table}

%\section{Lokale und Globale Beleuchtung}
	
\section{Rendertechniken}

\subsection{Raytracing}

	Raytracing ist ein verfahren, bei dem Ausgehend von der Lichtquelle, oder der Bildebene Strahlen in
	die Szene geschickt werden. 
	Strahlen, die auf ein ein Objekt treffen werden reflektiert, gestreut oder gebrochen. 
	Die Möglichkeiten hängen vom Verwendeten Modell der Oberfläche und des Lichtes ab.
	Nach der Wechselwirkung mit der Oberfläche können weitere Strahlen durch die Szene verfolgt werden.
	Dieser Vorgang wir meist Rekursiv aufgebaut und nach dem erreichen einer entsprechenden Rekursionstiefe
	wird dieser abgebrochen.
	Das Bild selbst entsteht durch die Aufakkumulierung der Lichtintensitäten, welche die Bildebene erreichen.
	Modell dieser Technik ist die Strahlenoptik, welche das Licht auf Strahlen reduziert die durch die Szene
	geschossen werden. Beugungsphänomene werden bei dieser Technik vernachlässigt.
 
\subsection{Path und Lighttracer}

\subsubsection{Lighttracer}

	Der Lighttracer ist eine Spezialisierung des Raytracers, bei dem die Wege des Lichtes grundlegend,
	ausgehend von der Lichtquelle berechnet werden. Hierbei werden die Strahlen bis zum erreichen eines
	Abbruchkriteriums durch die Szene verfolgt und anschließend mit der Bildebene verbunden.
	
\subsubsection{Pathtracer}

	Auch der Pathtracer stellt eine Spezialisierung des Raytracers da, bei dem die Lichtwege zum einem
	ausgehend von der Bildebene und gleichzeitig ausgehend von der Lichtquelle betrachtet werden.
	Nach erreichen des Abbruchkriteriums werden die Lichtwege ausgehend von der Lichtquelle und der
	Bildebene mit einander Kombiniert. Durch dieses Vorgehen ergeben sich wesentlich schnell mehr mögliche
	Lichtwege, als beim normalen Rayztracingalgorithmus.
	Der Pathtracer ist ein State-Of-the-Art Algorithmus zur Berrechnung der Globalen Beleuchtung.
	
\subsection{Raycasting}

	Raycasting stellt eine Vereinfachte Form des Raytracing da, bei dieser Technik wird die Berrechnung der
	Beleuchtung bereits nach der ersten Kollision zwischen Strahl und Objekt abgebrochen.
	Raycasting ist die Grundlage des in dieser Arbeit verwendeten Renderalgorithmus.

\section{Grundobjekte}

\subsection{Strahl}
	Der Strahl ist das Zentrale Element jedes Raytracing Algorithmus. Seine Mathematische Beschreibung ist
	denkbar einfach:
	
	\begin{equation}
	  	\underline{r}(t) = \underline{p} + t \cdot \vec{r} \text{, mit } t \in \mathbb{R}_+
	  	\label{eq:Strahl}
	\end{equation}	
	
	Jeder Punkt auf dem Strahl, hier durch $\underline{r}$ bezeichnet, ergibt sich aus der Addition eines Stützpunktes $\underline{p}$
	mit dem Produkt eines Richtungsvektor $\vec{r}$ und einem skalaren Wert $t$. Durch das Produkt $t \cdot \vec{r}$ wird der
	Richtungsvektor $\vec{r}$ beliebig gestaucht oder gestreckt.

\subsection{Kugel}

	Eine Kugelfläche wird im $\mathbb{R}^3$ mit dem Mittelpunkt $\underline{m} = (x_0, y_0, z_0)$ und dem Radius $r$ durch folgende
	Formel parametrisiert.

	\begin{equation}
		(x - x_0)^2 + (y - y_0)^2 + (z - z_0)^2 = r^2
		\label{eq:KugelGleichung1}
	\end{equation}
	
	Jeder Punkt $\underline{p} = (x, y, z)$ der die Formel \ref{eq:KugelGleichung1} erfüllt liegt auf der Oberfläche der Kugel.
	Die Formel \ref{eq:KugelGleichung1} lässt sich auf beliebige $\mathbb{R}^n\text{, mit } n \in \mathbb{N}_+$ erweitern.
	
	\begin{equation}
		\langle\underline{p} - \underline{m}, \underline{p} - \underline{m}\rangle = r^2
		\label{eq:KugelGleichung2}
	\end{equation}
	
	Durch diese Verallgemeinerung der Formel \ref{eq:KugelGleichung1} zur Formel \ref{eq:KugelGleichung2} ist die Beschreibung der
	Kugel jetzt unabhängig von der Dimension.

\section{Schnittpunktberechnung}

	Eine Kugel ist definiert durch ihren Mittelpunkt $\underline{m}$ und ihren Radius $r$. Wird der Mittelpunkt der Kugel auf
	den Koordinaten Ursprung verschoben, liegen alle Punkte $p$ auf der Oberfläche $O$, wenn sie denn Abstand $r$ zum Koordinatenursprung haben. Die zu erfüllende Bedingung hat demnach folgende Form:
	
	\begin{equation}
		\vert\vert\underline{p}\vert\vert = r
		\label{eq:KugelGleichungBedingun1}
	\end{equation}
	
	Die Bedingung aus Formel \ref{eq:KugelGleichungBedingun1} lässt sich Quartieren wodurch sich die folgende Kugelgleichung ergibt:
	
	\begin{equation}
		\langle\underline{p}, \underline{p}\rangle = r^2
		\label{eq:Schnittpunktberechnung1}
	\end{equation}
	
	Um den Schnittpunkt der Kugel mit dem Strahl aus der Formel \ref{eq:Strahl} zu Berechnen, wird der Strahl in die Gleichung \ref{eq:Schnittpunktberechnung1} eingesetzt und erhält die folgende Gleichung:
	
	\begin{equation}
		r^2 = \langle\underline{p}, \underline{p}\rangle = \langle r(t), r(t) \rangle
		\label{eq:Schnittpunktberechnung2}
	\end{equation}
	
	diese Gleichung gilt es umzustellen und nach $t$ aufzulösen:
	
	\begin{equation}
		r^2 = \langle r(t), r(t) \rangle = \langle \underline{p} + t \cdot \vec{r}, \underline{p} + t \cdot \vec{r} \rangle
		\label{eq:Schnittpunktberechnung3}
	\end{equation}
	
	\begin{equation}
		r^2 = \langle \underline{p}, \underline{p}\rangle + 2 \cdot \langle \underline{p}, \vec{r} \rangle \cdot t + \langle \vec{r}, \vec{r} \rangle \cdot t^2
		\label{eq:Schnittpunktberechnung4}
	\end{equation}
	
	Die Formel \ref{eq:Schnittpunktberechnung4} entspricht einer allgemeinen Quadratischen Gleichung:
	
	\begin{equation}
		a \cdot x^2 + b \cdot x + c = 0 \text{, mit } a \neq 0
		\label{eq:AllgemeineQuadratischeGleichung}
	\end{equation}
	
	Für die allgemeine Quadratische Gleichung lassen sich die Nullstellen folgendermaßen bestimmen:
	
	\begin{equation}
		x_{1,2} = \frac{-b \pm \sqrt{b^2 - 4 \cdot a \cdot c}}{2 \cdot a}
		\label{eq:AllgemeineQuadratischeGleichungLösungsFormel}	
	\end{equation}
	
	Wird die Gleichung \ref{eq:Schnittpunktberechnung4} mithilfe der Allgemeinen Lösungsformel \ref{eq:AllgemeineQuadratischeGleichungLösungsFormel} für Quadratische Gleichungen nach $t$ aufgelöst, ergeben sich für
	$t$ zwei Lösungen $t_1$ und $t_2$:
	
	\begin{equation}
		t_{1,2} = \frac{-2 \cdot \langle \underline{p}, \vec{r} \rangle \pm \sqrt{4 \cdot \langle \underline{p}, \vec{r} \rangle^2 - 4 \cdot \langle \underline{p}, \underline{p} \rangle \cdot \langle \vec{r}, \vec{r} \rangle}}{2 \cdot \langle \vec{r}, \vec{r} \rangle}
		\label{eq:Schnittpunktberechnung5}
	\end{equation}
	
	Die Diskriminante $D$ wird der Teil der Formel bezeichnet der im Zähler der Gleichung \ref{eq:Schnittpunktberechnung5} unter der
	Wurzel steht.
	
	\begin{equation}
		D = 4 \cdot \langle \underline{p}, \vec{r} \rangle^2 - 4 \cdot \langle \underline{p}, \underline{p} \rangle \cdot \langle \vec{r}, \vec{r} \rangle
		\label{eq:Diskriminante}
	\end{equation}
	
	Mit Hilfe der  Diskriminante $D$ lässt sich eine Aussage über die Schnittpunkte zwischen Strahl und Kugel formulieren. 
	Wenn gilt, dass $D < 0$, dann gibt es keine Lösung im Zahlenbereich $\mathbb{R}$, das heißt der Strahl schneidet die Kugel nicht.
	Gilt, dass $D = 0$ ist, dann trifft der Strahl die Kugel an genau einer Stelle und die beiden Lösungen $t_1$ und $t_2$ haben
	identische Werte. Wenn aber gilt, dass $D > 0$, dann ergeben sich genau zwei Schnittpunkte an den Stellen $t_1$ und $t_2$.
	Um die Punkte zu bestimmen, an dem der Strahl die Kugel trifft setzt man $t_1$ und $t_2$ einfach in die Gleichung \ref{eq:Strahl} ein.

\section{Die Perspektivische Kamera}

	Die für den einfachen Raycaster nötigen Gleichungen sind in den Obigen Teil bereits hergeleitet. Was jetzt noch benötigt wird
	ist eine Beschreibung für die Bildebene. Ausgehend von der Bildebene werden die Licht stahlen in die Szene geschossen.
	Anders als bei einem Rasterizer wird keine Kamera und keine Projektionsmatrix benötigt. Die Kamera konstruiert sich gerade heraus.
	Zu Beginn wird eine sehr einfache Kamera betrachtet, welche nicht rotiert und nicht verschoben wird.
	
	Das bedeutet, das es sich bei der Kamera um eine Ebene $E$ handelt welche mit der Folgenden Gleichung beschrieben wird:
	
	\begin{equation}
		E(u, v) = \underline{p_k} + u \cdot \vec{p}_0 + v \cdot \vec{p}_1 \text{, mit } u \in [-1, 1] \text{ und } v \in [-1, 1]
		\label{eq:KameraEbene}	
	\end{equation}
	
	Da unsere Kamera am Koordinaten Ursprung Positioniert werden soll, kann der Punkt $\underline{p}$ vorerst vernachlässigt werden.
	Die Spannvektoren $\vec{p}_0$ und $\vec{p}_1$ sind folgender maßen definiert:
	
	\begin{equation}
		\vec{p}_0 = \left(\begin{array}{c} 1 \\ 0 \\ 0 \end{array}\right) \text{, }
		\vec{p}_1 = \left(\begin{array}{c} 0 \\ 1 \\ 0 \end{array}\right)
		\label{eq:KameraSpannvektoren}	
	\end{equation}
	
	Die Auf diese Weise beschriebe Ebene wird in Pixel unterteilt. Dadurch definiert sich jeder Pixel, als Teilfläche der Kameraebene.
	Die Eckpunkte jedes Pixels lässt sich durch zwei Wertepaare genau beschreiben.
	Zum Schluss fehlt noch die Position der Kamera, welche durch den Positionsvektor $\underline{o}$ bezeichnet wird.
	Jeder Kamerastrahl bestimmt sich durch $\underline{o}$ und durch einen Richtungsvektor $\vec{d} = E(u, v) - \underline{o}$.
	Mit dieser Definition wird das Bild zu den Rändern hin gestreckt.
	
\section{Die Orthogonale Kamera}

	Eine weitere Möglichkeit eine Kamera zu definieren, besteht darin den Kameraursprung $\underline{o}$ in Abhängigkeit von $u$ und $v$ zu definieren, so dass alle Strahlen Parallel verlaufen.
	Die Bildebene wird wie in der Gleichung \ref{eq:KameraEbene} definiert mit den Spannvektoren aus \ref{eq:KameraSpannvektoren}. Die Definition der Ursprünge der Strahlen funktioniert analog zur Bildebene:
	
	\begin{equation}
		O(u, v) = \underline{p_o} + u \cdot \vec{p}_0 + v \cdot \vec{p}_1 \text{, mit } u \in [-1, 1] \text{ und } v \in [-1, 1]
		\label{eq:KameraOrthogonal}	
	\end{equation}
	
	Beide Gleichungen unterscheiden sich durch ihren Stützvektor. Der Stützvektor der Bildebene wird mit $\underline{p_k}$ bezeichnet und der, der Ursprünge $\underline{p_o}$. Im Einfachsten Fall definiert sich
	$\underline{p_k}$ als Nullvektor und $\underline{p_o}$ als der Vektor $(0, 0, -1)^T$.
	
\chapter{Ein analytischer Ansatz}
 
\section{Paradigma}

	In diesem Kapitel wird der Algorithmus hergeleitet welcher zum Zeichnen der Kugeln dient.
	Zum Beginn wird das Emission und Absorptionsmodell aus der Arbeit von \cite{Max:1995:OMD:614258.614298}
	genauer betrachtet. Als Grundannahme wird die Menge der Transferfunktionen auf lineare Funktionen beschränkt,
	die Dichte soll im Volumen als Konstant gelten. Diese Arbeit befasst sich mit der Frage, ob sich mit
	diesen Einschränkungen das entstehende Volumenintegral analytisch lösen lässt.
	Gibt es eine analytische Lösung, so würden sich die Bilder sehr effizient und korrekt berechnen lassen.
	Lässt sich Gleichung nicht analytisch Lösen, werden die Integrale so weit wie möglich analytisch gelöst
	und die restlichen Teile müssen Nummerisch approximiert werden.
	
\section{Das Optische Modell}

	Wie im vorherigen Abschnitt beschrieben baut das Modell auf dem von Nelsen Max aus der Arbeit \cite{Max:1995:OMD:614258.614298} auf. Zur Herleitung seiner Formel betrachtete er Partikel in Form
	von Einheitskugeln. Jede dieser Kugeln besitzt einen Radius $r$. Die Oberfläche eines Partikel $A$
	bestimmt sich durch das Produkt der Kreiszahl $\pi$ und dem Radius. So das gilt $A = \pi \cdot r$.
	Die Mittlere Dichte $\rho$ entspricht der Anzahl von Partikeln, welche in einem Einheitsvolumen zu finden sind.
	Betrachtet wird im folgenden ein Zylinder, welcher mit der Kreisfläche $E$ und einer Länge $\Delta s$ parametrisiert wird. 
	Das Volumen eines solchen Zylinders entspricht $V_z = E \cdot \delta s$ und es enthält in etwa $N$ Partikel, mit $N = \rho E \delta s$.
	Die von dem Zylinder verdeckte Grundfläche $B$ entspricht bei einem sehr klein gewählten $\delta s$ in etwa $NA$, mit $NA = \rho AE \delta s$.
	Als Flussrichtung des Lichtes wird $\delta s$ gewählt. Der Anteil des Lichts, welcher mit Teilchen Wechselwirkt bis er $B$ erreicht beträgt $\rho A \delta s$. 
	Wenn $\delta s$ gegen Null geht, sinkt die Wahrscheinlichkeit, das sich Gaspartikel entlang der Lichtrichtung überlappen. Die Funktion $I(s)$ liefert die Intensität des Lichtes an der Distanz $s$. Wird die Lichtintensität
	$I(s)$ nach $s$ abgeleitet, ergibt sich die folgender Differenzialgleichung:
		 
	\begin{equation}
		\frac{dI}{ds} = -\rho(s)AI(s) = -\tau(s)I(s)
		\label{eq:MAX95grundDG}
	\end{equation}
	
	Auf der rechten Seite der Gleichung \ref{eq:MAX95LSGgrundDG} steht die Funktion $\tau(s)$, diese beschreibt
	die Abschwächung der Lichtintensität durch ein Volumen der Länge $s$. Wie in \ref{eq:MAX95EmissionDG} zusehen
	ist definiert sich der Abschwächungskoeffizient als das negative Produkt der mittleren Dichte $\rho$ mit der
	Oberfläche eines Partikels. Nelson Max hat die folgende Lösung für die Differenzialgleichung gefunden:
	
	\begin{equation}
		I(s) = I_0 \cdot e^{- \int\limits_{0}^{s} \tau(t) dt}
		\label{eq:MAX95LSGgrundDG}
	\end{equation}
	
	Der Parameter $I_0$ entspricht der Intensität an der Stelle $s = 0$, dabei handelt es sich um den Punkt,
	an dem der Lichtstrahl auf das Volumen trifft. Bei den zweiten Teil des Terms handelt es sich um die Transparenz
	des Mediums im Intervall $[0, s]$, welche durch $T(s) = exp(- \int_{0}^{l} \tau(t) dt)$ repräsentiert wird. 
	Nelson Max definiert neben der Transparenz einen Wert für den Grad an
	Verdeckung durch das Volumen $\alpha$, der im Englischen als \textit{opacity} bekannt ist.
	
	\begin{equation}
		\alpha = 1 - T(l) = 1 - e^{- \int\limits_{0}^{l} \tau(t) dt}
		\label{eq:MAX95Opacity}
	\end{equation}
	
	Ist die Funktion $\tau$ innerhalb des Volumens konstant, vereinfacht sich der Term für die Verdeckung zur Gleichung $\alpha = 1 - exp(-\tau l) = \tau l - (\tau l)^2 / 2 + \cdots$. 
	Im Rahmen dieser Arbeit ist der Begriff der Transferfunktion bereit mehr als einmal gefallen,
	eine solche Funktion bildet den Materialwert auf die optischen Eigenschaften der Gleichung ab.
	
\subsection{Emssion}

	Wie in der Arbeit \cite{Max:1995:OMD:614258.614298} wird auch in dieser zuerst die Gleichung für die Emission
	hergeleitet. Neben der Abschwächung der Lichtintensität durch ein Volumen, kann zusätzlich an jedem Punkt in diesem Licht emittiert werden. In Worten bedeutete es, das ein Lichtstrahl welcher durch das Volumen geschossen
	wurde zusätzlich mit Licht angereichert wird. Zur Herleitung der Emission soll die Absorption zu nächst vernachlässigt werden. Betrachtet werden die Partikel aus dem vorhergehenden Abschnitt, jeder dieser Partikel
	wird im Folgenden als Transparent angenommen. Zusätzlich emittiert jeder von ihnen diffuses Licht. Das bedeutet
	jeder Partikel emittiert Licht, in alle Richtungen mit der gleichen Intensität $C$ über der projizierten Fläche $\rho A E \Delta s$. Dieser Effekt bewirkt eine Anreicherung des Lichtfluss $C \rho A E \Delta s$ welcher zur Basisfläche $E$ fließt.
	Durch diesen Zusammenhang ergibt sich eine weitere Differenzialgleichung:
	
	\begin{equation}
		\frac{dI}{ds} = C(s)\rho(s)A = C(s)\tau(s) = g(s)
		\label{eq:MAX95EmissionDG}
	\end{equation}
	
	Die Funktion $g(s)$ wird als Quellterm bezeichnet. Dieser Term beschreibt die Wechselwirkung des Lichtes mit dem
	Volumen über der Länge $s$. Zu der Differenzialgleichung \ref{eq:MAX95EmissionDG} hat Nelson Max ebenfalls eine
	Lösung gefunden welche sich wie folgt definiert:
	
	\begin{equation}
			I(s) = I_0 + \int\limits_{0}^{s} g(t) dt
			\label{eq:MAX95LSGEmissionDG}
	\end{equation}
	
	Ein Problem dieser Lösung ist die Abhängigkeit zwischen der Ausdehnung des Mediums und des Emissionsfaktors.
	Es gibt keine obere Schranke, das bedeutet, das die Emittierte Lichtenergie sehr schnell die Szene mit Licht
	überfluten kann und die Abbildung der Materialparameter in Abhängigkeit der Objektgrößen gewählt werden müssen.
	
	
\section{Optical Models for Direct Volume Rendering}
	
\subsection{Emission}

	
\subsection{Absorption und Emission}

	In der Vorhergehenden Abschnitt wurden die Volumen als vollkommen Transparent betrachtet, dieses Verhalten soll sich jetzt ändern.
	Das Licht, welches das Volumen durchläuft wird soll mit Hilfe des Abschwächungskoeffizient abgeschwächt werden und zusätzlich durch
	die Emission angereichert werden:
	
	\begin{equation}
		\frac{dI}{ds} = g(s) - \tau(s)I(s)
		\label{eq:MAX95EmissionAbsorptionDG}
	\end{equation}
	
	In seiner Arbeit entwickelt Nelson Max eine Lösung für beliebige Quellfunktionen, welche $g(s)$ annehmen kann. 
	Dabei wird das Licht als Strahl von der Lichtquelle durch das Medium geschickt. 
	Die Variable $s$ entspricht dem Laufparameter des Strahls,
	welcher an der Position der Lichtquelle den Wert Null annimmt und den Wert $D$ am Sensor hat.
	
	\begin{equation}
		I(D) = I_0 \cdot e^{-\int\limits_{0}^{D}\tau(t)dt} + \int\limits_{0}^{D}g(s) \cdot e^{-\int\limits_{s}^{D}\tau(t)dt}ds
		\label{eq:MAX95LSGEmissionAbsorptionDG1}
	\end{equation}
	
	\begin{equation}
		I(D) = I_0T(D) + \int\limits_{0}^{D}g(s)T'(s)ds
		\label{eq:MAX95LSGEmissionAbsorptionDG2}
	\end{equation}
	
	Wobei die Transparenz über die einzelnen Werte von s sich als $T'(s) = e^{-\int\limits_{s}^{D}\tau(x)dx}$ definiert. Das Integral aus der Gleichung \ref{eq:MAX95LSGEmissionAbsorptionDG1} lässt sich für einige Transferfunktionen analytisch lösen für die anderen schlägt Nelson Max die
	Approximation durch Riemannsummen vor. Ist der Faktor $C(s)$ eine Konstante $C$, lässt sich die Lösung stark vereinfachen. und das Licht,
	welches den Sensor erreicht ergibt sich durch die Gleichung:
	
	\begin{equation}
		I(D) = I_0 T(D) + C(1 - T(D))
		\label{eq:MAX95LSGEmissionAbsorptionWithCKonstDG1}
	\end{equation}
	
	Die Lichtundurchlässigkeit $\alpha = (1 - T(D))$ und entspricht der Wahrscheinlichkeit, dass ein Strahl, welcher vom Sensor in Richtung der Lichtquelle
	geschossen wird einen Partikel trifft und die Farbe C zu sehen ist. 
	
\subsection{Streuung und Schatten}

	Die bisher vorgestellten Gleichungen erzeugen bereits schöne Bilder, entsprechen allerdings noch nicht der Realität. Licht welches auf ein Partikel
	trifft wird gestreut, es entstehen Schatten. Nelson Max geht dabei auf die Grundlagen der Streuung ein, in dem der Quellterm $g(s)$ um einen Winkelparameter erweitert wird. 
	Der Quellterm wird im Folgenden mit $g(X, \omega) = E(X) + S(X, \omega)$. 
	$E(X)$ bezeichnet die Emission an einen bestimmten Punkt $X$ und $S(X, \omega)$ die Richtung in welche das Licht gestreut wird. Trifft das Licht ein Partikel an einem Punkt $X$, wird dessen Intensität
	mit einer \textit{brdf} Funktion multipliziert. \textit{Brdf} steht für 
	\textit{bidirectional reflection distribution function}, welche die Verteilung des Lichtes in Abhängigkeit
	des Einfalls und Ausfallwinkels an dem Punkt $X$ bestimmt. 
	Die Streufunktion $S(X, \omega) = r(X, \omega, \omega') \cdot i(X, \omega)$ setzt sich zusammen aus der
	\textit{brdf} welche hier durch die Funktion $r$ dargestellt wird und der Intensität des Lichtes $i$,
	welches aus der Winkelrichtung $\omega'$ in den Punkt $X$ einfällt. Mit Hilfe eines rekursiven \textit{Raytracers} kann der Lichtanteil reduziert werden, was einen Schattenwurf zur Folge hat.
	
\section{An Analytical Ray Casting of Volume Data}

	Diese Arbeit baut auf der Grundlage von CT, MRI, SPECT und PET Datenmengen auf. Das bedeutet, alles was
	vorliegt ist ein 3D-Array von skalaren Werten, welche im Folgenden als Dichte interpretiert werden.
	Das hier vorgestellte Verfahren baut auf einen \textit{Raycaster} auf, das heißt es werden ausgehend vom
	Bildsensor Stahlen in die Szene geschossen. Das Resultat ist ein Bild, welches durch die Abschwächung der
	Hintergrundbeleuchtung durch das Volumen entsteht. Durch den Einsatz von Interaktionstechniken, kann
	der Nutzer im Folgenden Teile des Volumen durch die Veränderung der Dichtewerte ausblenden oder hervorheben.
	Die meisten \textit{Raycast}-Ansätze approximieren diesen Vorgang nummerisch, da das finden, von Analytischen
	Lösungen, insofern möglich nicht einfach ist. In dieser Arbeit wird ein Verfahren vorgestellt,
	welches zum Teil die Aufkommenden Integrale Analytisch löst und wenn nötig auf Numerische Praktiken zurückgreift.
	
\subsection{Levoy's raycast algorithm}

	Grundlage dieser Arbeit ist ein \textit{Raycast}-Algorithmus von Levoy. Die betrachtete Welt besteht aus
	einem Regulären Gitter, wobei jede Zelle ein Voxel darstellt. Jeder dieser Voxel hat 8 Nachbarn.
	Im folgenden beschreibt $r$ einen Strahl, welcher in die Szene geschossen wird. Jeder Punkt entlang
	des Strahls lässt sich über die Länge $u$ vom Beginn des Strahls bis zu dem entsprechenden Punkt bestimmen.
	Zusätzlich wird eine Funktion $\alpha_C(u)$ definiert, welche die akkumulierten Verdeckungen vom Punkt an der
	Stelle $u$ bis zum Pixel liefert. Diese Funktion repräsentiert die Abschwächung des Lichtes durch das Volumen.
	$\Delta u$ definiert eine bestimmte Länge auf dem Strahl zwischen zwei benachbarten Stützpunkten.
	Ein Stützpunkt wird in dieser Arbeit mit $u_i$ bezeichnet. Die Abschwächung des Lichtes an einem
	gewählten Stützpunkten wird über die Formel $\alpha(u_i) \Delta u_i$ berechnet. Wie in der Arbeit von
	Nelson Max berechnet sich die Transparenz durch $1 - \alpha_C(u)$. 
	$u + \Delta u$ ist ein Punkt mit der Transparenz $1 - \alpha_C(u + \Delta u)$. Die Transparenz
	zwischen den Punkt $u$ und $u + \Delta u$ wird mit $1 - \alpha(u) \Delta u$ angegeben.
	Die Transparenz zwischen dem Pixel und dem Punkt $u + \Delta u$ setzt sich folgendermaßen zusammen:
	
	\begin{equation}
		1 - \alpha_C(u + \Delta u) = (1 - \alpha_C(u)) \cdot (1 - \alpha(u)\Delta u)
		\label{eq:TransparenzGL1}
	\end{equation}
	
	Daraus ergibt sich eine rekursive Beziehung für die aufakkumulierten Verdeckungen für $\alpha_C(u)$
	
	\begin{equation}
		\alpha_C(u + \Delta u) = \alpha_C(u) + \alpha(u)(1 - \alpha_C(u)) \Delta u
		\label{eq:TransparenzGL2}
	\end{equation}
	
	Bezeichnet $C_C(u)$ die akkumulierte Farbe, lässt diese sich mit einer ähnlichen rekursiven Formel
	berechnen. $C(u)$ stellt die Farbe dar, welche von einem Punkt, mit dem Längenparameter $u$ durch
	ein vollkommen transparentes Volumen auf den Pixel Reflektiert wird. Zur Berechnung der Farbintensität
	wird das Phong Beleuchtungsmodell benutzt. In der Realität ist das Medium zwischen dem Punk an der Stelle $u$
	und dem Pixel selten vollkommen Transparent, deshalb muss die Farbe durch das Volumen abgeschwächt werden.
	$C(u) \alpha(u) \Delta u$ beschreibt diese Abschwächung.
	
	\begin{equation}
		C_C(u + \Delta u) = C_C(u) + (1 - \alpha_C(u)) \cdot C(u) \alpha(u) \Delta u
		\label{eq:TransparenzGL3}
	\end{equation}
	
\subsection{Eine kontinuierliche Formulierung}

\section{Verdeckung}

Die endgültige Lichtintensität, die das Auge erreicht setzt sich zusammen aus:
 
$I = I_E + I_B + I_L$

dem emittierten Licht:

$I_E = \int\limits_{t_n}^{t_f} \tau(t_n, t) \cdot c(v_r(t)) dt $

dem ambienten Licht:

$I_B = \tau(t_n, t_f) \cdot I_b$

$\tau(t_0, t_1) = e^{- \int\limits_{t_0}^{t_1} \sigma (v_r(t)) dt}$

und dem Licht der Einzelnen Lichtquellen. Hier reduziert auf einen einzelnen Strahl der den Sichtstrahl $\underline{r}(t) = \underline{e} + t \cdot \vec{v}$ im Volumen schneidet. (An der Stelle t)

$I_L(t) = \tau(t_n, t) \cdot I_p(t)$

$I_p(t) = e^{- \int\limits_{0}^{l(t)} \cdot  \sigma (v_r(s)) ds} \cdot I_p$

$I_p(t) = e^{- \int\limits_{0}^{l(t)} \cdot  \lambda \cdot v_r(s) ds} \cdot I_p$

$I_p(t) = e^{- \int\limits_{0}^{l(t)} \cdot  \lambda \cdot \kappa ds} \cdot I_p$

$I_p(t) = e^{- \int\limits_{0}^{l(t)} \cdot  \lambda \cdot \kappa ds} \cdot I_p$

$I_p(t) = e^{- \lambda \cdot \kappa \cdot \int\limits_{0}^{l(t)} ds} \cdot I_p$

$I_p(t) = e^{- \lambda \cdot \kappa \cdot s} \cdot I_p$

$I_p(t) = e^{- \lambda \cdot \kappa \cdot \frac{-<p(t), d(t)>}{<d(t), d(t)>} + \frac{\sqrt{<p(t), d(t)>^2 - <p(t), p(t)> \cdot <d(t), d(t)>}}{<d(t), d(t)>}} \cdot I_p$

mit $d(t) = d$ da es sich um eine Richtungslichtquelle handelt

$I_p(t) = e^{- \lambda \cdot \kappa \cdot \frac{-<p(t), d>}{<d, d>} + \frac{\sqrt{<p(t), d>^2 - <p(t), p(t)> \cdot <d, d>}}{<d, d>}} \cdot I_p$

$I_{L(t)} = \tau(t_n, t) \cdot e^{- \lambda \cdot \kappa \cdot \frac{-<p(t), d>}{<d, d>} + \frac{\sqrt{<p(t), d>^2 - <p(t), p(t)> \cdot <d, d>}}{<d, d>}} \cdot I_p$

Daraus ergibt sich $I_L$ für eine Richtungslichtquelle

$I_L = \int\limits_{t_n}^{t_f} I_{L(t)} dt $

$I_L = \int\limits_{t_n}^{t_f} \tau(t_n, t) \cdot I_{p(t)} dt$

$I_L = \int\limits_{t_n}^{t_f} \tau(t_n, t) \cdot e^{- \lambda \cdot \kappa \cdot \frac{-<p(t), d>}{<d, d>} + \frac{\sqrt{<p(t), d>^2 - <p(t), p(t)> \cdot <d, d>}}{<d, d>}} \cdot I_p dt$


\cite{Max:1995:OMD:614258.614298}

\cite{conf/pg/JungPP98}

\chapter{Fazit}

%\chapter{title}
%
%\chapter{ein kapitel}
%\section{eine Grafik}
%\begin{figure}[htbp]
%	\centering
%		\includegraphics{test.png}
%	\caption{beschriftung}
%	\label{fig:diplominf}
%\end{figure}

\end{document}