\documentclass[hyperref,german,beleg,final,twoside]{cgvpub}
%weitere Optionen zum Ergänzen (in eckigen Klammern):
% 
% female	weibliche Titelbezeichnung bei Diplom
% bibnum	numerische Literaturschlüssel
% final 	für Abgabe	
% lof			Abbildungsverzeichis
% lot			Tabellenverzeichnis
% noproblem	keine Aufgabenstellung
% notoc			kein Inhaltsverzeichnis
% twoside		zweiseitig

\usepackage{tabularx}

\author{Josef Schulz}
\title{Ground-Truth-Renderer für Partikelbasierte Daten}
\birthday{20. Oktober 1989}
\placeofbirth{Dresden}
\matno{3658867}

\betreuer{Dipl-MedienInf. Joachim Staib}
\bibfiles{literatur.bib}
\problem{
Die Darstellung von Partikeldaten mittels Kugelglyphen ist in wissenschaftlichen Visualisierung
inzwischen etabliert. Gerade bei dichten Datensätzen stellen kompakte Anordnungen von sehr vielen
Kugeln jedoch ein Problem für die Erkennbarkeit der zu visualisierenden Vorgänge dar. Eine Möglichkeit, diesem Problem zu begegnen ist es, über Blinn-Phong-Beleuchtung hinausgehende Effekte wie
globale Schatten oder den Einsatz von Methoden aus dem Volume-Rendering zu integrieren. Durch
deren Komplexität muss in Echtzeitvisualisierungen jedoch auf teilweise grobe Approximationen zu-
rückgegriffen werden. Die Einschätzung der Approximationsqualität fällt häufig schwer, da keine Visualisierung des exakten Verfahrens verfügbar ist.
Ziel dieser Belegarbeit ist die Umsetzung eines CPU-Renderers für Partikeldaten, der eine Reihe
von erweiterten Visualisierungseffekten unterstützt. Er soll die Grundlage für Ground-Truth-
Visualisierungen bieten.
Zunächst soll eine geeignete Softwarearchitektur konzipiert und umgesetzt werden. Die Partikel sollen als mit lichtemittierendem und ?absorbierendem Gas gefüllte Kugeln interpretiert werden. Es sollen anschließend Methoden entwickelt werden, um einen physikalisch plausiblen globalen Schattenwurf und Lichttransport für eine beliebige Anzahl an Punkt- und Richtungslichtquellen zu ermöglichen.
Die dafür notwendigen Gleichungen für Kugeln mit konstanter Dichte und Emission, sowie linearer
Absorption, sollen soweit wie möglich analytisch bestimmt und, sobald nicht mehr möglich, mittels
möglichst exakter numerischer Integratoren ausgewertet werden.

Die Teilaufgaben umfassen:

\begin{itemize}
\item Umfassende Literaturrecherche zur globalen Beleuchtungsrechnung in der Volumen Visualisierung
\item Schrittweise Konzeption und Umsetzung einer erweiterbaren Architektur zum Erzeugen von Ground-Truth-Bildern:

	\begin{enumerate}
		\item Zunächst als Raytracer für opake Kugeln, der globale Schatteneffekte von frei
		positionierbaren Punkt- und Richtungslichtquellen unterstützt
		\item Umsetzung eines Renderers, der Kugeln als Volumen nach dem Emissions-Absorptions-Modell rendert, dabei analytische Bestimmung des Volume-Rendering-Integrals, einschließlich Integration direkter Beleuchtung unverdeckter Lichtquellen
		\item Erweiterung zu verdeckten Lichtquellen und Bestimmung der Lichtstärke- und Farbe
		für Lichtstrahlen durch verdeckende Kugeln
	\end{enumerate}
\item Unterstützung für ein Standardformat wie VRML
\item Evaluation in Bezug auf Korrektheit, Bildartefakte und (numerische) Grenzfälle
\end{itemize}
\newpage
Optional:
\begin{itemize}
\item Unterstützung für Refraktionseffekte
\item Unterstützung komplexerer Materialtypen
\end{itemize}
}

\copyrighterklaerung{Hier soll jeder Autor die von ihm eingeholten
Zustimmungen der Copyright-Besitzer angeben bzw. die in Web Press
Rooms angegebenen generellen Konditionen seiner Text- und
Bild"ubernahmen zitieren.}

\acknowledgments{Die Danksagung...}
	
	 
\begin{document}

\chapter{Einleitung}

\section{Motivation}
	
	Bei einer Vielzahl von Messvorgängen oder Simulationen ergeben sich Partikel basierte Datensätze.
	Erst durch eine geeignete Darstellung lassen sich diese optimal auswerten und analysieren.
	Das Ziel von Visualisierungen ist die Unterstützung der menschlichen Wahrnehmung bei der Auswertung
	der erhobenen Daten.
	Dabei geht nicht um eine bloße Optische Verschönerung der Darstellung, sondern darum kodierte Eigenschaften 
	in den Fokus des Betrachter zu rücken und Tendenzen hervorzuheben.
	Die Darstellung von dreidimensionalen Partikeln auf eine zweidimensionalen Ebene ist mit Problemen verbunden,
	diese sollen im Folgenden näher betrachtet und werden.
	
	Die Fähigkeit des Menschen die Tiefe von Objekten in einer Szene schätzen zu können wird durch ein System ermöglicht,
	das den Wert für die Tiefe auf unterschiedlichen Wegen bestimmt. Ein Weg besteht in der Schätzung der Entfernung über
	die Epipolargeometrie. Bei der Betrachtung eines zweidimensionalen Bildes kann diese Variante lediglich die Bildschirmebene erfassen, jedoch nicht die Tiefe der abgebildeten Objekte. Die Objekttiefen in der Abbildung
	kann der Mensch anhand von Überdeckungen und durch eine perspektivische Transformation der Objekte abschätzen.
	Damit Überdeckungen erkannt und die abgebildeten Objekte von einander unterschieden werden können müssen sich diese
	sich durch einen Kontrast voneinander unterscheiden, Schattierungen lösen dieses Problem. Zusätzlich wirkt ein Kugelglyph plastischer als wenn er durch einen einfarbiger Kreis darstellen werden würde. 	
	Überdeckungen verhindern allerdings, das der Betrachte die dahinter liegenden Partikel sehen kann. 
	Ganze Strukturformen zu denen beispielsweise Höhlen zählen können deshalb nicht erfasst werden.
	Eine Möglichkeit dieses Problem zu lösen besteht darin die Partikel transparent abzubilden, damit trotz
	der Überdeckung alle Strukturen sichtbar bleiben.
	Die zuvor erwähnten Schattierungen ergeben sich in der realen Welt aus der Wechselwirkung zwischen Licht und
	Materie. Ein weiter Weg zur Bestimmung von Objekttiefen die der Mensch nutzt, ist die Rekonstruktion von
	Lichtwegen. 
	
	Lokale Beleuchtungsmodelle eigen sich zur Berechnung von Schattierung, unterstützen die Wahrnehmung der Tiefe jedoch nur bedingt.
	Es existieren eine reihe von Beleuchtungsmodellen die die Szene global Beleuchten. 
	Der Einsatz solcher Modelle stellt eine bessere Unterstützung der Wahrnehmung dar.
	Existierenden Algorithmen müssen auf Grund einer hohe Rechenkomplexität, der globalen Beleuchtung an vielen stellen approximativ vereinfachen.
	Insbesondere GPU-Implementierung sind auf diese angewiesen um die globale Beleuchtung in Echtzeit zur realisieren.
	
	Ziel dieser Arbeit ist die Entwicklung eines CPU-Renderes für Partikel, bei dem der Fokus auf der Genauigkeit und nicht auf der Geschwindigkeit der Berechnung liegt.
	Die Partikel werden als mit Gas gefüllte Kugel interpretiert und mit einem Verfahren der direkten Volumen Darstellung
	gezeichnet. Direkte Verfahren zerlegen die Daten nicht in einem Vorverarbeitungsschritt in Netze aus Polygonen,
	sondern visualisieren die Daten in einem Schritt.
	Die Grundlage des Verfahrens stellt ein Volumenintegral dar, dessen Lösung mit Hilfe eines Raycast-Algorithmus
	dargestellt wird. Dabei handelt es sich um ein halb-analytisches Verfahren.
	Vorteile analytischer Lösungen in der Genauigkeit und der Geschwindigkeit der Berechnung.  
	Die erzeugten Bilder, dienen als \textit{Ground-Truth} Information zur Evaluation von approximativen Implementierungen. Im Folgenden werden Verwandte Arbeiten und der Aufbau dieser Arbeit Vorgestellt.
	
\section{Verwandte Arbeiten}

	Die Arbeit \cite{JSYR14} fast verschiedenen Algorithmen zur Beleuchtung und interaktiven Darstellung
	von Volumendaten in Echtzeit zusammen.
	Vorgestellte Algorithmen werden hinsichtlich ihrer technischen Umsetzung, Performance und ihrer
	Unterstützung für die menschliche Wahrnehmung klassifiziert.  
	Diese Kriterien erleichtern die Auswahl des Verfahrens für den Entwickler in Abhängigkeit der Anwendung.
	Bei den Verfahren handelt es sich um approximative Varianten mit dem Ziel interaktive Bildraten zu
	gewährleisten.
	
	Die Grundlagen des Emission-Absorption-Modells werden von Nelson Max in der Arbeit \cite{Max:1995:OMD:614258.614298} beschrieben.
	Das Volumenintegral des Emission-Absorption-Modells wird hergeleitet und Stück für Stück mit Effekten
	angereichert. Neben der einfachen Streuung und der Schattenberechnung wird auch die Mehrfachstreuung vorgestellt.
	Beendet wir die Arbeit mit der Vorstellung anwendbarer Lösungsverfahren.
	
	In der Publikation \cite{conf/pg/JungPP98} wird ein zum Teil Analytisches Verfahren vorgestellt. 
	Der Algorithmus wird zur Darstellung von Voxelgittern eingesetzt.  
	Jedem Voxel wird eine Dichte zu geordnet, aus welcher ein Wert für die Transparenz abgeleitet wird.
	Hinter dem Voxelgitter befindet sich eine Lichtquelle und deren Lichtintensität wird durch das Volumen  unterschiedlich Stark abgeschwächt. 
	Die Integrale der Gleichungen werden streckenweise Analytisch gelöst, wodurch ein Zuwachs an 
	Genauigkeit erreicht wird. 
	
	In der Arbeit \cite{journals/tvcg/AmentSW13} geht es um einen alternativen Ansatz, welcher nicht auf dem Emission und Absorptionsmodell aufbaut, sondern von einem Punkt Stahlen in die umliegende Nachbarschaft verfolgt um den
	Grad an Verdeckung an diesem Punkt zu bestimmen. Je mehr Segmente mit hoher Dichte in der Nachbarschaft liegen,
	umso geringer ist der Anteil des Lichtes, welches eben jenen Punkt erreicht. Ein Geschwindigkeitszuwachs wird durch eine Vor-integrierte Transferfunktion erreicht. Ein Vorteil dieses Verfahrens, stellt die Güte der erzeugten
	Schatten da.

	Photonen Mapping ist ein Verfahren zur Erzeugung von Globalen Beleuchtungseffekten, dieses kommt
	in der Arbeit \cite{JKRY12} zur Beleuchtung von Volumendaten in Echtzeit zum Einsatz.
	Die benötigte dazu benötigte Photonenmap wir dabei mit Histogrammen realisiert. 
	Mit deren Hilfe können Änderungen in Interaktiven Bildwiederholungsraten ermöglicht werden,
	da bei Parameteränderungen nur die betroffenen Histogramme neu erzeugt werden müssen.
	
	Die Monte Carlo Methode ist ein Verfahren zur nummerischen Approximation von Integralen, dieses
	kommt zur Lösung der Volumengleichung in der Arbeit \cite{KPB12a} zum Einsatz. Der Fokus liegt
	der Arbeit liegt auf der physikalischen Grundlage der Gleichung. Die Arbeit verspricht eine
	Globale Beleuchtungsberechnung in Echtzeit und unterstützt unter anderen auch Mehrfachstreuungen.

	Ambiente Verdeckung kommt in der Arbeit \cite{journals/tvcg/KnissPHSM03} zum Einsatz. 
	Mit Hilfe des so genannten \textit{blurring} werden die Farbanteile des Indirekten Lichtes in einem Buffer gehalten. Dieses verfahren approximiert die Streuungseffekte, welche in Materialien auftreten können.
	Eine Erweiterung dieses Verfahrens stellt die Arbeit \cite{10.1111:j.1467-8659.2009.01464.x} dar, welche hier nur der Vollständigkeit halber erwähnt werden soll.
	
\section{Aufbau der Arbeit}

	Die Arbeit ist folgendermaßen gegliedert. Zunächst werden im Grundlagen Kapitel die Technik des Raycastings erläutert und
	die grundlegenden Gleichungen für Kugel und Strahl und deren Schnitt behandelt. 
	Beendet wird das zweite Kapitel mit der Herleitung der Perspektivischen	Kamera anhand einer Lochkamera. 
	Im dritten Kapitel wird die Rendergleichung aufbauend auf der Arbeit von Nelson Max hergeleitet und eine Lösung
	dieser präsentiert werden.
	Das vierte Kapitel wird die sich mit der Implementierung des Algorithmus beschäftigen und im fünften Kapitel werden die
	Ergebnisse in Abhängigkeit der Parameter und der Rechenzeit evaluiert und anschließend im Fazit diskutiert werden.
	
\chapter{Grundlagen}

	Der Entwickelte Algorithmus basiert auf dem Verfahren des \textit{Raycasting}. Bei diesem Verfahren wird
	der Sensor der Kamera, welche am ende dieses Kapitels definiert wird, diskretisiert und für jeden Pixel
	wird mindestens ein Strahl in die Szene geschossen. 
	Für jeden Strahl muss eine Schnittberechnung mit den in der Szene befindlichen Objekten durchgeführt werden. 
	Wird ein Objekt vom Strahl geschnitten, muss die Rendergleichung für das dazugehörige Stahlsegment gelöst werden.
	
	In dieser Arbeit wird die Menge der Objekte auf Kugeln reduziert. Jede Kugel repräsentiert ein mit Gas gefüllten
	Partikel. Die Dichte im Inneren jedes Partikels wird als Konstant angenommen und die Menge der Transferfunktionen
	auf Lineare beschränkt werden. Im Folgenden werden die Gleichungen für Strahlen, Kugeln und deren Schnittberechnung
	definiert. Das Kapitel wird mit der Herleitung der perspektivischen Kamera beendet.
	
	Punkte werden in dieser Arbeit wie Vektoren behandelt, sie unterscheiden sich von diesen in den Formeln dadurch das sie
	Unterstrichen sind und keinen Pfeil besitzen wie ein Vektor. $\underline p$ stellt einen Punkt und $\vec{p}$ einen
	Vektor dar. Skalarprodukte werden mit Hilfe von spitzen Klammern $\langle \vec{a}, \vec{b} \rangle$ repräsentiert.

\section{Strahl und Kugelgleichung}

	Es wird mit der Definition des Strahls begonnen, der das Zentrale Element des Algorithmus bildet. Die Formel
	beschreibt wie jeder Punkt auf dem Strahl in Abhängigkeit eines skalaren Wertes $t$, eines Stützpunktes $\underline{o}$
	und einem Richtungsvektor $r$ bestimmt werden kann. Die Gleichung definiert sich wie folgt:
	
	\begin{equation}
	  	\underline{p}(t) = \underline{o} + t \cdot \vec{r} \text{, mit } t \in \mathbb{R}_+
	  	\label{eq:Strahl}
	\end{equation}
	
	Jeder Punkt auf dem Strahl $\underline{p}(t)$, ergibt sich aus der Addition eines Stützpunktes $\underline{o}$ mit dem durch $t$ skalierten Richtungsvektor $\vec{r}$. Der Vektor $\vec{r}$ muss normiert sein, die Länge des Vektors muss genau 1 betragen:
	$\left\|\left|\vec{r}\right|\right| = 1$.
	Ist der Wert von $t < 0$ liegt der Punkt hinter dem Ausgangspunkt des Strahls, andernfalls
	davor oder im Fall von $t = 0$ entspricht er eben diesen.
	
	Neben dem Strahl ist die Kugel, welche die Geometrische Form der betrachteten Partikel darstellt eine wichtige Rolle und soll
	ebenfalls definiert werden, damit die Schnittpunktberechnung durchgeführt werden kann.
	
	Die Fläche einer Kugel wird im $\mathbb{R}^3$ durch den Mittelpunkt $\underline{m} = (x_0, y_0, z_0)$ und den Radius $r$ parametrisiert. Jeder Punkt auf der Kugeloberfläche lässt sich durch den Abstand zum Mittelpunkt, dem Zentrum der Kugel definieren.
	Die Folgende Formel beschreibt diese Formulierung:
	
	\begin{equation}
		(x - x_0)^2 + (y - y_0)^2 + (z - z_0)^2 = r^2
		\label{eq:KugelR3}
	\end{equation}
	
	Jeder Punkt $\underline{p} = (x, y, z)$ der die Formel \ref{eq:KugelR3} erfüllt liegt auf der Oberfläche der Kugel.
	Die Kugelgleichung \ref{eq:KugelR3} lässt sich auf beliebige $\mathbb{R}^n\text{, mit } n \in \mathbb{N}_+$ erweitern,
	und die Beschreibung ist für alle $n$ äquivalent:
	
	\begin{equation}
		\langle\underline{p} - \underline{m}, \underline{p} - \underline{m}\rangle = r^2
		\label{eq:Kugel}
	\end{equation}

	Um den Schnittpunkt zwischen Kugel und Strahl zu berechnen wird die Kugelgleichung \ref{eq:Kugel} vereinfacht.
	Der Mittelpunkt der Kugel auf den Koordinaten Ursprung verschoben, liegen alle Punkte $p$ auf der Oberfläche $O$, wenn sie denn Abstand $r$ zum Koordinatenursprung haben. Die zu erfüllende Bedingung hat demnach folgende Form:
	
	\begin{equation}
		\vert\vert\underline{p}\vert\vert = r
		\label{eq:KugelEasy}
	\end{equation}
	
	Die Gleichung \ref{eq:KugelEasy} lässt sich Quartieren und der Strahl wird anschließend in diese eingesetzt. Das Resultat
	ist eine quadratische Gleichung. Bis auf das Skalar $t$ sind alle Werte bekannt. Die Gleichung
	
	\begin{equation}
			r^2 = \langle\underline{p}, \underline{p}\rangle = \langle r(t), r(t) \rangle = \langle \underline{p} + t \cdot \vec{r}, \underline{p} + t \cdot \vec{r} \rangle
			\label{eq:StrahlInKugel}
	\end{equation}
	
	kann nach $t$ umgestellt werden und die Nullstellen berechnet werden. Es gibt entweder keine, eine oder zwei Lösungen für die
	Gleichung. Werden die bestimmten Schnittpunkte in die Gleichung des Strahls eingesetzt können die Positionen der Schnittpositionen
	berechnet werden. Die Komplette Lösungsformel definiert sich im Folgenden:
	
	\begin{equation}
		t_{1,2} = \frac{-2 \cdot \langle \underline{p}, \vec{r} \rangle \pm \sqrt{4 \cdot \langle \underline{p}, \vec{r} \rangle^2 - 4 \cdot \langle \underline{p}, \underline{p} \rangle \cdot \langle \vec{r}, \vec{r} \rangle}}{2 \cdot \langle \vec{r}, \vec{r} \rangle}.
		\label{eq:Schnittpunkte}
	\end{equation}
	

\section{Die Perspektivische Kamera}

	Um in der realen Welt Bilder aufzunehmen wird eine Kamera benötigt, hier wird eine Simulation durchgeführt
	und für diese wird das Modell einer Kamera benötigt welches sich von der \textit{camera obscura} ableitet.
	Dabei handelt es sich um das Modell einer Lochkamera, diese besteht aus einem Kasten. Auf der einen Seite
	befindet sich ein Lichtempfindliches Material, welches den Sensor bildet und auf der an gegenüberliegenden
	Seite befindet sich ein schmales Loch. Das Licht wird von der Oberfläche der Abzubildenden Objekte reflektiert
	und fällt durch Loch auf den Sensor. Bei dem Vorgang der Abbildung findet eine Vertikale und Horizontale
	Spiegelung der Szene statt. Das bedeutet das Bild der Szene wird spiegelverkehrt aufgenommen.
	
	\begin{figure}[h]
		\centering
		\def\svgwidth{5cm}
		\input{images/cameraObscura.pdf_tex}
		\caption{Schematische Darstellung des Abbildungsvorgangs der \textit{camera obscura}}
		\label{fig:cameraObscura}
	\end{figure}
	
	Die Abbildung \ref{fig:cameraObscura} zeigt den Aufbau der \textit{Camera obscura} schematisch.
	Auf der Linken Seite der Abbildung befindet sich die Bildebene, auf welche die Szene abgebildet wird.
	In der Mitte der Abbildung \ref{fig:cameraObscura} befindet sich die Wand mit dem kleinen Loch.
	Hier wird die erste Abstraktion durchgeführt, denn in der Realität kann das Loch eine gewisse Größe nicht
	unterschreiten, da andernfalls kein Licht hindurch dringen würde. Aufgrund dieser minimalen Größe kommt
	es zu einer Glättung der Abbildung. Diese Einschränkung gilt für die Computersimulation nicht, es wird
	angenommen, dass das Loch unendlich klein ist, so dass die Szene unendlich genau Abgebildet werden kann.
	
	Auf der rechten Seite in der Abbildung \ref{fig:cameraObscura} befindet sich ein Objekt in Form einer Strecke,
	welche durch die Punkte $A$ und $B$ begrenzt wird. Der Punkt $B$ befindet sich mit der Sensormitte und dem
	Loch genau auf einer Ebene und er wird auf den Punkt $B'$ abgebildet. 
	Der zweite Punkt $A$ wird auf dem Punkt $A'$ abgebildet. Genauer zeigt die Abbildung \ref{fig:cameraObscura} den
	Strahlensatz der in diesem Zusammenhang gilt. 
		 
	Die Distanz zwischen dem Sensor und dem Loch der Kamera wird mit der Variable $f$ bezeichnet. Da es sich wie
	oben bereits erwähnt um eine Computersimulation handelt kann das Modell weiter abstrahiert werden.
	In der im Computer simulierten Welt kann der Sensor auch vor dem Loch positioniert werden, was zur Folge hat,
	das die Abbildung entspiegelt wird. 
	
	Die Position der Kamera soll im Folgenden mit der Variable $\underline{p}$ bezeichnet werden. Diese ist
	mit der Position des Lochs der Lochkamera identisch und wird in der Literatur auch als Augpunkt bezeichnet.
	Für jeden Pixel der Bildebene wird mindestens ein Strahl erzeugt, welcher als Stützpunkt die Position
	der Kamera erhält und der Richtungsvektor ist der Normierte Vektor von der Kamerapostion zum Pixel.
	Zur Vereinfachung wird angenommen, dass die Bildebene parallel zur xy-Ebene des Koordinatensystems der Szenen ist
	und der Augpunkt genau im Ursprung von diesem liegt.
	Die Fläche des Sensors wird in $W \cdot H$ Pixeln unterteilt.
	Für jeden Pixel $(x, y)$ wird ein Strahl $s$ in die Szene geschossen, dessen Stützpunkt der Augpunkt der Kamera
	ist und der Richtungsvektor der normierte Vektor $\vec{r}(x, y)$ welche sich ohne wie folgt definiert.
	
	\begin{equation}
		\vec{r}(x, y) = \left( 
							\begin{array}{l}
								(\frac{x}{W} \cdot 2 - 1) \cdot \frac{W}{H} \\
								\frac{y}{H} \cdot (- 2) + 1 \\
								f
							\end{array}							
					 	\right)
		\label{eq:direction}
	\end{equation}
	
	Es ist gilt zu beachten das der Richtungsvektor noch normiert werden muss: $\vec{r}(x, y) =  \frac{\vec{r}(x, y)}{\left|\left|\vec{r}(x, y)\right|\right|}$. 
	Jeder Kamera Strahl, im folgenden auch als Primärstrahl bezeichnet hat die folgende Form:
	
	\begin{equation}
		\underline{s} (x, y) = \underline{p} + t \cdot \vec{r}(x, y)
		\label{eq:primaryRay}
	\end{equation}
	
	Die Kamera kann an dieser Stelle nur entlang der z-Achse Blicken, eine Rotation im Raum lässt sich durch die Multiplikation
	einer Rotationsmatrix mit den Richtungsvektoren bewerkstelligen. Die Position des Kameramodells ist frei Wählbar, es genügt den
	Augpunkt zu verschieben. Mit Hilfe der Distanz $f$, der fokalen Länge kann ein Zoomeffekt der Kamera erzielt werden.
	
\chapter{Rendergleichung}

	Die Basis der Beleuchtungsrechnung in dieser Arbeit bildet ein Volumenintegral, welches die Verteilung des Lichtes
	in der Szene beschreibt. Die Gleichung fußt auf dem Emission und Absorptionsmodell von Nelson Max aus der Arbeit \cite{Max:1995:OMD:614258.614298}. 
	
	Grundlage der Herleitung bilden Partikel in Form von Einheitskugeln. Jede dieser Kugeln besitzt einen Radius $r = 1$. 
	Die projizierte Oberfläche einer Kugel entspricht einem Kreis, und dessen Flächeninhalt lässt sich aus dem Produkt des 
	quadrierten Radius mit der Kreiszahl $\pi$ bestimmen.
	Die Anzahl von Partikeln, welche sich in einem Einheitsvolumen befinden wird mit $\rho$ bezeichnet.
	Im folgenden soll ein Zylinder betrachtet werden, welcher mit der Kreisfläche $E$ und einer Länge $\Delta s$ parametrisiert. 
	Das Volumen des Zylinders entspricht $V_z = E \cdot \delta s$ und es enthält in etwa $N = \rho E \delta s$ Partikel.
	Die von dem Zylinder verdeckte Grundfläche $B$ entspricht bei einem sehr klein gewählten $\delta s$ in etwa $NA$, mit $NA = \rho AE \delta s$.
	Als Flussrichtung des Lichtes wird $\delta s$ gewählt. Der Anteil des Lichts, welcher mit Teilchen Wechselwirkt bis er $B$ erreicht beträgt $\rho A \delta s$. 
	Wenn $\delta s$ gegen Null geht, sinkt die Wahrscheinlichkeit, das sich Gaspartikel entlang der Lichtrichtung überlappen. 
	Die Funktion $I(s)$ liefert die Intensität des Lichtes an der Distanz $s$. Wird die Lichtintensität
	$I(s)$ nach $s$ abgeleitet, ergibt sich die folgender Differenzialgleichung:
		 
	\begin{equation}
		\frac{dI}{ds} = -\rho(s)AI(s) = -\tau(s)I(s)
		\label{eq:MAX95grundDG}
	\end{equation}
	
	Auf der rechten Seite der Gleichung \ref{eq:MAX95LSGgrundDG} steht die Funktion $\tau(s)$, diese beschreibt
	die Abschwächung der Lichtintensität durch ein Volumen mit der Länge $s$. Wie in \ref{eq:MAX95EmissionDG} zusehen
	ist definiert sich der Abschwächungskoeffizient als das negative Produkt der mittleren Dichte $\rho$ mit der
	Oberfläche eines Partikels. Nelson Max hat die folgende Lösung für die Differenzialgleichung gefunden:
	
	\begin{equation}
		I(s) = I_0 \cdot e^{- \int\limits_{0}^{s} \tau(t) dt}
		\label{eq:MAX95LSGgrundDG}
	\end{equation}
	
	Der Parameter $I_0$ entspricht der Intensität an der Stelle $s = 0$, dabei handelt es sich um den Punkt,
	an dem der Lichtstrahl auf das Volumen trifft. Bei den zweiten Teil des Terms handelt es sich um die Transparenz
	des Mediums im Intervall $[0, s]$, welche durch $T(s) = exp(- \int_{0}^{l} \tau(t) dt)$ repräsentiert wird. 
	Nelson Max definiert neben der Transparenz einen Wert für den Grad an Verdeckung durch das Volumen $\alpha$, der in 
	der Englischen Literatur als \textit{opacity} bekannt ist.
	
	\begin{equation}
		\alpha = 1 - T(l) = 1 - e^{- \int\limits_{0}^{l} \tau(t) dt}
		\label{eq:MAX95Opacity}
	\end{equation}
	
	Ist die Funktion $\tau$ innerhalb des Volumens konstant, vereinfacht sich der Term für die Verdeckung zur Gleichung $\alpha = 1 - exp(-\tau l) = \tau l - (\tau l)^2 / 2 + \cdots$. 
	Im Rahmen dieser Arbeit ist der Begriff der Transferfunktion bereit mehr als einmal gefallen,
	eine solche Funktion bildet den Materialwert auf die optischen Eigenschaften der Gleichung ab.
	
\subsection{Emission}

	Wie in der Arbeit \cite{Max:1995:OMD:614258.614298} wird auch in dieser zuerst die Gleichung für die Emission
	hergeleitet. Neben der Abschwächung der Lichtintensität durch ein Volumen, kann zusätzlich an jedem Punkt in diesem Licht emittiert werden. In Worten bedeutete es, das ein Lichtstrahl welcher durch das Volumen geschossen
	wurde zusätzlich mit Licht angereichert wird. Zur Herleitung der Emission soll die Absorption zu nächst vernachlässigt werden. Betrachtet werden die Partikel aus dem vorhergehenden Abschnitt, jeder dieser Partikel
	wird im Folgenden als Transparent angenommen. Zusätzlich emittiert jeder von ihnen diffuses Licht. Das bedeutet
	jeder Partikel emittiert Licht, in alle Richtungen mit der gleichen Intensität $C$ über der projizierten Fläche $\rho A E \Delta s$. Dieser Effekt bewirkt eine Anreicherung des Lichtfluss $C \rho A E \Delta s$ welcher zur Basisfläche $E$ fließt.
	Durch diesen Zusammenhang ergibt sich eine weitere Differenzialgleichung:
	
	\begin{equation}
		\frac{dI}{ds} = C(s)\rho(s)A = C(s)\tau(s) = g(s)
		\label{eq:MAX95EmissionDG}
	\end{equation}
	
	Die Funktion $g(s)$ wird als Quellterm bezeichnet. Dieser Term beschreibt die Wechselwirkung des Lichtes mit dem
	Volumen über der Länge $s$. Zu der Differenzialgleichung \ref{eq:MAX95EmissionDG} hat Nelson Max ebenfalls eine
	Lösung gefunden welche sich wie folgt definiert:
	


	$I = I_B + I_E$
	
		\begin{figure}[h]
			\centering
			\includegraphics[width=10cm]{/home/josef/test.pdf}
			\caption{Schematische Darstellung des Abbildungsvorgangs der \textit{camera obscura}}
			\label{fig:dasdcameraObscura}
		\end{figure}
	

\chapter{Implementation}

\chapter{Evaluation und Diskussion}
\section{Fazit}

%\chapter{title}
%
%\chapter{ein kapitel}
%\section{eine Grafik}
%\begin{figure}[htbp]
%	\centering
%		\includegraphics{test.png}
%	\caption{beschriftung}
%	\label{fig:diplominf}
%\end{figure}

\end{document}