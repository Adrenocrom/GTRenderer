\documentclass[hyperref,german,beleg,final]{cgvpub}
%weitere Optionen zum Ergänzen (in eckigen Klammern):
% 
% female	weibliche Titelbezeichnung bei Diplom
% bibnum	numerische Literaturschlüssel
% final 	für Abgabe	
% lof			Abbildungsverzeichis
% lot			Tabellenverzeichnis
% noproblem	keine Aufgabenstellung
% notoc			kein Inhaltsverzeichnis
% twoside		zweiseitig

\usepackage{tabularx}

\author{Josef Schulz}
\title{Ground-Truth-Renderer für Partikelbasierte Daten}
\birthday{20. Oktober 1989}
\placeofbirth{Dresden}
\matno{3658867}

\betreuer{Dipl-MedienInf. Joachim Staib}
\bibfiles{literatur}
\problem{
Die Darstellung von Partikeldaten mittels Kugelglyphen ist in der wissenschaftlichen Visualisierung
inzwischen etabliert. Gerade bei dichten Datensätzen stellen kompakte Anordnungen von sehr vielen
Kugeln jedoch ein Problem für die Erkennbarkeit der zu visualisierenden Vorgänge dar. Eine Möglichkeit, diesem Problem zu begegnen ist es, über Blinn-Phong-Beleuchtung hinausgehende Effekte wie
globale Schatten oder den Einsatz von Methoden aus dem Volume-Rendering zu integrieren. Durch
deren Komplexität muss in Echtzeitvisualisierungen jedoch auf teilweise grobe Approximationen zu-
rückgegriffen werden. Die Einschätzung der Approximationsqualität fällt häufig schwer, da keine Visualisierung des exakten Verfahrens verfügbar ist.
Ziel dieser Belegarbeit ist die Umsetzung eines CPU-Renderers für Partikeldaten, der eine Reihe
von erweiterten Visualisierungseffekten unterstützt. Er soll die Grundlage für Ground-Truth-
Visualisierungen bieten.
Zunächst soll eine geeignete Softwarearchitektur konzipiert und umgesetzt werden. Die Partikel sollen als mit lichtemittierendem und ?absorbierendem Gas gefüllte Kugeln interpretiert werden. Es sollen anschließend Methoden entwickelt werden, um einen physikalisch plausiblen globalen Schattenwurf und Lichttransport für eine beliebige Anzahl an Punkt- und Richtungslichtquellen zu ermöglichen.
Die dafür notwendigen Gleichungen für Kugeln mit konstanter Dichte und Emission, sowie linearer
Absorption, sollen soweit wie möglich analytisch bestimmt und, sobald nicht mehr möglich, mittels
möglichst exakter numerischer Integratoren ausgewertet werden.

Die Teilaufgaben umfassen:

\begin{itemize}
\item Umfassende Literaturrecherche zur globalen Beleuchtungsrechnung in der Volumen Visualisierung
\item Schrittweise Konzeption und Umsetzung einer erweiterbaren Architektur zum Erzeugen von Ground-Truth-Bildern:

	\begin{enumerate}
		\item Zunächst als Raytracer für opake Kugeln, der globale Schatteneffekte von frei
		positionierbaren Punkt- und Richtungslichtquellen unterstützt
		\item Umsetzung eines Renderers, der Kugeln als Volumen nach dem Emissions-Absorptions-Modell rendert, dabei analytische Bestimmung des Volume-Rendering-Integrals, einschließlich Integration direkter Beleuchtung unverdeckter Lichtquellen
		\item Erweiterung zu verdeckten Lichtquellen und Bestimmung der Lichtstärke- und Farbe
		für Lichtstrahlen durch verdeckende Kugeln
	\end{enumerate}
\item Unterstützung für ein Standardformat wie VRML
\item Evaluation in Bezug auf Korrektheit, Bildartefakte und (numerische) Grenzfälle
\end{itemize}
\newpage
Optional:
\begin{itemize}
\item Unterstützung für Refraktionseffekte
\item Unterstützung komplexerer Materialtypen
\end{itemize}
}
\copyrighterklaerung{Hier soll jeder Autor die von ihm eingeholten
Zustimmungen der Copyright-Besitzer angeben bzw. die in Web Press
Rooms angegebenen generellen Konditionen seiner Text- und
Bild"ubernahmen zitieren.}
\acknowledgments{Die Danksagung...}

\begin{document}

\chapter{Einleitung}

	Ein Photon das im inneren der Sonne emittiert wird, ist dem kurzwelligen Spektrum der elektromagnetischen Wellen zugeordnet. Es handelt sich um Gammastrahlung. 
	Auf seiner langen Reise vom Kern bis zur Korona, 
	die rund 150.000 Jahre dauert, wird das Photon durch das enorm dichte und
	heiße Gas der Sonne blau verschoben.
	Auf den rund 690.000 km, die das Photon durch die Sonne wandert, absorbiert die Sonne
	einen großen Teil der Energie des Photons. Nachdem es die Sonne verlassen hat, benötigt
	das Photon weitere 8 Minuten um unsere Erde zu erreichen. 
	Die Geschichte von der Langen Reise dieses einzelnen Photons ist ein extremes Beispiel
	für den Vorgang der im Folgenden betrachtet wird.
	
	Licht ist im Physikalischen Sinn ein noch nicht gänzlich erfasstes Phänomen.
	Es zeigen sich Charakteristika von Wellen und von Teilchen, es wird vom
	Welle-Teilechodualismus gesprochen. Dieses wunderbare Modell ist ein Deckmantel
	für viele Fragen, die sich im Zusammenhang mit der Ausbreitung des Lichtes in unserer
	Welt ergeben und noch nicht alle beantwortet sind.
	
	Die Optik ist in der Physik die Lehre des Lichtes, sie beschreibt die Ausbreitung des Lichts
	und die Wechselwirkung mit Materie. In der Optik gibt es verschiedene Modelle, welche die
	Eigenschaften des Lichtes beschreiben.
	
	Die Strahlenoptik betrachtet das Licht in Form von Strahlen. Diese Modell approximiert 
	das Licht als Strahl, der von der Lichtquelle aus in die Welt geschossen wird.
	Diese Vereinfachung kann genutzt werde, wenn die Größenordnungen der Objekte, welche im
	Zusammenhang mit Licht betrachtet werden, deutlich über der Wellenlänge des Lichts liegt.
	Ist dies erfüllt können Typische Welleneigenschaften, wie Beugung und daraus resultierende
	Interferenz vernachlässigt werden.
	Für die Berechnung von Schatten, Reflexion und Brechung eignet sich die Strahlenoptik
	ausgesprochen gut und soll für diese Arbeit Grundlage der Betrachtung sein.
	Die Lichtstrahlen breiten sich immer nur geradlinig aus, bis sie auf einen Körper treffen und
	reflektiert, gestreut oder gebrochen werden. Sie können einander durchdringen ohne sich gegenseitig zu beeinflussen. 
	Der Weg des Lichtes lässt sich umkehren, was zur folge hat,
	dass die Gesetzt auch bei umgekehrter Lichtrichtung gelten.
	Dieses Prinzip ist essentiell für die Implementierung welche im Folgenden betrachtet wird,
	da die Strahlen von der Kamera aus in die Welt geschossen werden.
	
	Die Beleuchtung einer Computergenerierten Szene wird in vielen Implementierungen, die
	aus Computerspielen und anderen Visualisierungen bekannt sind stark vereinfacht.
	Diese Modelle lassen die Landschaften in einem schönen Licht erscheinen, vernachlässigen
	jedoch Physikalische Gesetzmäßigkeiten, wie die Erhaltung von Energie.
	Die Berechnung von Schatten welche sich durch den Weg des Lichtes ergeben sollten,
	werden oftmals nur sehr vereinfacht berechnet, insofern sie vorhanden sind.
	
	Für die meisten Anwendungen sind diese Approximationen vollkommen ausreichend.
	In der Computergrafik hat sich die Repräsentation von Daten mithilfe von Kugelglyphen
	bewährt. Als Beispiel soll das Modell eines Moleküls dienen.
	Ein Problem welches sich aus der Projektion auf den Bildschirm ergibt, ist die 
	Tiefenwahrnehmung des Menschen. Die durch den Computergenerierten Bilder sind in der Regel
	zweidimensionale Projektionen von dreidimensionalen Szenen. Der Mensch benötigt zur Erkennung
	von Lagenbeziehungen der Objekte in der Szene weitere Informationen.
	Im Laufe des Lebens lernt ein Mensch, die Merkmale des Lichtes zu Interpretieren.
	Auf diese Weise gelingt es einem Betrachter, die Lage der Lichtquelle nur aus einer Objekt
	Silhouette zu schätzen.
	Um diese Fähigkeit nutzen zu können wird jedoch eine komplexe Beleuchtung der Szene nötig.
	
\chapter{Verwandte Arbeiten}

\section{Optical Models for Direct Volume Rendering}

	Die Arbeit von Nelson Max gehört zu den meist Zitierten Arbeiten im Bereich des Volumen Renderns und behandelt
	die Grundlagen des Emission und Absorptionsverhalten Gas gefüllten Volumen.
	Zur Herleitung der Gleichung nutzt Nelson Max Partikel in Form von Einheitskugeln, diese besitzen einen Radius $r$
	und somit die Projizierte Oberfläche $A = \Pi \cdot r$. 
	Die Mittlere Dichte $\rho$ entspricht der Anzahl von Partikeln innerhalb des Einheitsvolumen.
	Betrachtet wird ein Zylinder, der mit der Kreisfläche $E$ und einer Länge $\Delta s$ parametrisiert wird. 
	Das Volumen des Zylinders entspricht $V_z = E \cdot \delta s$ und enthält demnach $N$ Partikel, mit $N = \rho E \delta s$.
	Die von dem Zylinder verdeckte Grundfläche $B$ entspricht bei einem sehr klein gewählten $\delta s$ in etwa $NA$, mit $NA = \rho AE \delta s$.
	Als Flussrichtung des Lichtes wird $\delta s$ gewählt. Der Anteil des Lichts, welcher mit Teilchen Wechselwirkt bis er $B$ erreicht beträgt
	$\rho A \delta s$. Wenn $\delta s$ gegen Null geht, sinkt die Wahrscheinlichkeit, das sich Gaspartikel entlang der Lichtrichtung überlappen.
	
	Es ergibt sich die Folgende Differenzialgleichung:
	
	 
	\begin{equation}
		\frac{dI}{ds} = -\rho(s)AI(s) = -\tau(s)I(s)
		\label{eq:MAX95grundDG}
	\end{equation}
	
	In der Gleichung \ref{eq:MAX95grundDG} beschreibt $s$ die Länge entlang des Lichtstrahles. $I(s)$ stellt die Lichtintensität an der Stelle des Volumens
	dar, an dem der Strahl genau die Länge $s$ besitzt. $\tau(s) = \rho(s)A$ wird als Abschwächungskoeffizient bezeichnet. $\tau$ beschreibt den Grad der Abschwächung des Lichtes durch ein Volumen.
	
	\begin{equation}
		I(s) = I_0 \cdot e^{- \int_{0}^{s} \tau(t) dt}
		\label{eq:MAX95LSGgrundDG}
	\end{equation}
	 
	Gleichung \ref{eq:MAX95LSGgrundDG} ist die Lösung von \ref{eq:MAX95grundDG}. Das Integral über den Abschwächungskoeffizienten, wird von Nelson Max als Transparenz $T(s)$ von $0$ bis $s$ bezeichnet. Die Lichtundurchlässigkeit $\alpha$, im Englischen \textit{opacity} berechnet sich aus $\alpha = 1 - T(s)$.
	
\subsection{Emission}
	
	Wird die Lichtintensität an einem Bestimmten Punkt auf einem Lichtstrahl betrachtet, welcher von der Lichtquelle durch ein Medium zu der
	Projektionsoberfläche geschossen wird, lässt sich diese durch Reflektionen und Emission von Licht an diesem Punkt weiter anreichern.
	Nelson Max betrachtet in seiner Arbeit den Einfacheren Fall, bei dem nur Licht emittiert wird. Die Absorption von Licht durch die Partikel 
	wird in der nächsten Sektion behandelt. 
	Wie beschrieben sollen die Partikel im Folgenden als Vollkommen Transparent betrachtet werden, mit der Eigenschaft Licht zu emittieren.
	Das Licht, welches von den Partikeln emittiert wird strahlt Diffuse mit konstanter Intensität $C$ über der Fläche $A$.
	Die Menge des Lichtes, welches durch $B$ fließt entspricht $C \rho AE \delta s$. Für die Einheitsfläche $A$ entspricht dieser Fluss $C \rho A \delta s$.
	Aus dieser Annahme ergibt sich eine weitere Differenzialgleichung:
	
	\begin{equation}
		\frac{dI}{ds} = C(s)\rho(s)A = C(s)\tau(s) = g(s)
		\label{eq:MAX95EmissionDG}
	\end{equation}
	
	Mit $g(s)$ ist die Intensität des emittierten Lichtes gemeint. Die Lösung lässt sich zu folgender Formel vereinfachen, wenn die Reflektionen aus
	der Betrachtung heraus genommen werden:
	
	\begin{equation}
		I(s) = I_0 + \int_{0}^{s} g(t) dt
		\label{eq:MAX95LSGEmissionDG}
	\end{equation}
	
	Mit dieser Lösung ergibt sich ein Problem, denn das Integral ist nicht durch eine Obere Schranke beschränkt. Das bedeutet, dass das die Lichtintensität
	die Aufnahmefähigkeit des Sensors schnell überschreitet und C deshalb nur sehr kleine Werte annehmen kann. $I_0$ ist wie in der Gleichung \ref{eq:MAX95LSGgrundDG} als Hintergrundstrahlung definiert und kann für jeden Strahl unabhängig gewählt werden.
	
\subsection{Absorption und Emission}

	In der Vorhergehenden Abschnitt wurden die Volumen als vollkommen Transparent betrachtet, dieses Verhalten soll sich jetzt ändern.
	Das Licht, welches das Volumen durchläuft wird soll mit Hilfe des Abschwächungskoeffizient abgeschwächt werden und zusätzlich durch
	die Emission angereichert werden:
	
	\begin{equation}
		\frac{dI}{ds} = g(s) - \tau(s)I(s)
		\label{eq:MAX95EmissionAbsorptionDG}
	\end{equation}
	
	In seiner Arbeit entwickelt Nelson Max eine Lösung für beliebige Quellfunktionen, welche $g(s)$ annehmen kann. 
	Dabei wird das Licht als Strahl von der Lichtquelle durch das Medium geschickt. 
	Die Variable $s$ entspricht dem Laufparameter des Strahls,
	welcher an der Position der Lichtquelle den Wert Null annimmt und den Wert $D$ am Sensor hat.
	
	\begin{equation}
		I(D) = I_0 \cdot e^{-\int\limits_{0}^{D}\tau(t)dt} + \int\limits_{0}^{D}g(s) \cdot e^{-\int\limits_{s}^{D}\tau(t)dt}ds
		\label{eq:MAX95LSGEmissionAbsorptionDG1}
	\end{equation}
	
	\begin{equation}
		I(D) = I_0T(D) + \int\limits_{0}^{D}g(s)T'(s)ds
		\label{eq:MAX95LSGEmissionAbsorptionDG2}
	\end{equation}
	
	Wobei die Transparenz über die einzelnen Werte von s sich als $T'(s) = e^{-\int\limits_{s}^{D}\tau(x)dx}$ definiert. Das Integral aus der Gleichung \ref{eq:MAX95LSGEmissionAbsorptionDG1} lässt sich für einige Transferfunktionen analytisch lösen für die anderen schlägt Nelson Max die
	Approximation durch Riemannsummen vor. Ist der Faktor $C(s)$ eine Konstante $C$, lässt sich die Lösung stark vereinfachen. und das Licht,
	welches den Sensor erreicht ergibt sich durch die Gleichung:
	
	\begin{equation}
		I(D) = I_0 T(D) + C(1 - T(D))
		\label{eq:MAX95LSGEmissionAbsorptionWithCKonstDG1}
	\end{equation}
	
	Die Lichtundurchlässigkeit $\alpha = (1 - T(D))$ und entspricht der Wahrscheinlichkeit, dass ein Strahl, welcher vom Sensor in Richtung der Lichtquelle
	geschossen wird einen Partikel trifft und die Farbe C zu sehen ist. 
	
\subsection{Streuung und Schatten}

	Die bisher vorgestellten Gleichungen erzeugen bereits schöne Bilder, entsprechen allerdings noch nicht der Realität. Licht welches auf ein Partikel
	trifft wird gestreut, es entstehen Schatten. Nelson Max geht dabei auf die Grundlagen der Streuung ein, in dem der Quellterm $g(s)$ um einen Winkelparameter erweitert wird. 
	Der Quellterm wird im Folgenden mit $g(X, \omega) = E(X) + S(X, \omega)$. 
	$E(X)$ bezeichnet die Emission an einen bestimmten Punkt $X$ und $S(X, \omega)$ die Richtung in welche das Licht gestreut wird. Trifft das Licht ein Partikel an einem Punkt $X$, wird dessen Intensität
	mit einer \textit{brdf} Funktion multipliziert. \textit{Brdf} steht für 
	\textit{bidirectional reflection distribution function}, welche die Verteilung des Lichtes in Abhängigkeit
	des Einfalls und Ausfallwinkels an dem Punkt $X$ bestimmt. 
	Die Streufunktion $S(X, \omega) = r(X, \omega, \omega') \cdot i(X, \omega)$ setzt sich zusammen aus der
	\textit{brdf} welche hier durch die Funktion $r$ dargestellt wird und der Intensität des Lichtes $i$,
	welches aus der Winkelrichtung $\omega'$ in den Punkt $X$ einfällt. Mit Hilfe eines rekursiven \textit{Raytracers} kann der Lichtanteil reduziert werden, was einen Schattenwurf zur Folge hat.
	
\section{An Analytical Ray Casting of Volume Data}

	Diese Arbeit baut auf der Grundlage von CT, MRI, SPECT und PET Datenmengen auf. Das bedeutet, alles was
	vorliegt ist ein 3D-Array von skalaren Werten, welche im Folgenden als Dichte interpretiert werden.
	Das hier vorgestellte Verfahren baut auf einen \textit{Raycaster} auf, das heißt es werden ausgehend vom
	Bildsensor Stahlen in die Szene geschossen. Das Resultat ist ein Bild, welches durch die Abschwächung der
	Hintergrundbeleuchtung durch das Volumen entsteht. Durch den Einsatz von Interaktionstechniken, kann
	der Nutzer im Folgenden Teile des Volumen durch die Veränderung der Dichtewerte ausblenden oder hervorheben.
	Die meisten \textit{Raycast}-Ansätze approximieren diesen Vorgang nummerisch, da das finden, von Analytischen
	Lösungen, insofern möglich nicht einfach ist. In dieser Arbeit wird ein Verfahren vorgestellt,
	welches zum Teil die Aufkommenden Integrale Analytisch löst und wenn nötig auf Numerische Praktiken zurückgreift.
	
\subsection{Levoy's raycast algorithm}

	Grundlage dieser Arbeit ist ein \textit{Raycast}-Algorithmus von Levoy. Die betrachtete Welt besteht aus
	einem Regulären Gitter, wobei jede Zelle ein Voxel darstellt. Jeder dieser Voxel hat 8 Nachbarn.
	Im folgenden beschreibt $r$ einen Strahl, welcher in die Szene geschossen wird. Jeder Punkt entlang
	des Strahls lässt sich über die Länge $u$ vom Beginn des Strahls bis zu dem entsprechenden Punkt bestimmen.
	Zusätzlich wird eine Funktion $\alpha_C(u)$ definiert, welche die akkumulierten Verdeckungen vom Punkt an der
	Stelle $u$ bis zum Pixel liefert. Diese Funktion repräsentiert die Abschwächung des Lichtes durch das Volumen.
	$\Delta u$ definiert eine bestimmte Länge auf dem Strahl zwischen zwei benachbarten Stützpunkten.
	Ein Stützpunkt wird in dieser Arbeit mit $u_i$ bezeichnet. Die Abschwächung des Lichtes an einem
	gewählten Stützpunkten wird über die Formel $\alpha(u_i) \Delta u_i$ berechnet. Wie in der Arbeit von
	Nelson Max berechnet sich die Transparenz durch $1 - \alpha_C(u)$. 
	$u + \Delta u$ ist ein Punkt mit der Transparenz $1 - \alpha_C(u + \Delta u)$. Die Transparenz
	zwischen den Punkt $u$ und $u + \Delta u$ wird mit $1 - \alpha(u) \Delta u$ angegeben.
	Die Transparenz zwischen dem Pixel und dem Punkt $u + \Delta u$ setzt sich folgendermaßen zusammen:
	
	\begin{equation}
		1 - \alpha_C(u + \Delta u) = (1 - \alpha_C(u)) \cdot (1 - \alpha(u)\Delta u)
		\label{eq:TransparenzGL1}
	\end{equation}
	
	Daraus ergibt sich eine rekursive Beziehung für die aufakkumulierten Verdeckungen für $\alpha_C(u)$
	
	\begin{equation}
		\alpha_C(u + \Delta u) = \alpha_C(u) + \alpha(u)(1 - \alpha_C(u)) \Delta u
		\label{eq:TransparenzGL2}
	\end{equation}
	
	Bezeichnet $C_C(u)$ die akkumulierte Farbe, lässt diese sich mit einer ähnlichen rekursiven Formel
	berechnen. $C(u)$ stellt die Farbe dar, welche von einem Punkt, mit dem Längenparameter $u$ durch
	ein vollkommen transparentes Volumen auf den Pixel Reflektiert wird. Zur Berechnung der Farbintensität
	wird das Phong Beleuchtungsmodell benutzt. In der Realität ist das Medium zwischen dem Punk an der Stelle $u$
	und dem Pixel selten vollkommen Transparent, deshalb muss die Farbe durch das Volumen abgeschwächt werden.
	$C(u) \alpha(u) \Delta u$ beschreibt diese Abschwächung.
	
	\begin{equation}
		C_C(u + \Delta u) = C_C(u) + (1 - \alpha_C(u)) \cdot C(u) \alpha(u) \Delta u
		\label{eq:TransparenzGL3}
	\end{equation}
	
\subsection{Eine kontinuierliche Formulierung}
	
\chapter{Grundlagen}

	In diesem Kapitel soll die verwendete Rendertechnik Begrifflich genauer abgegrenzt werden.
	Im Folgenden werden alle benötigten Mathematischen Formeln hergeleitet und erklärt.
	Am ende dieses Kapitels wird der Aufbau der Perspektivischen Kamera, 
	welche hier zum Einsatz kommt genau erläutert. 

\section{Verwendete Formelzeichen}

   \begin{table}[htbp]
     \centering
		\begin{tabularx}{\textwidth}{l|X}
  			\textbf{Formelzeichen} & \textbf{Erläuterung}  \\
  			\hline
  			$\mathbb{R}_+$						& Bezeichnet die Menge der Reellen Zahlen im Intervall $[0, \infty)$ \\
  			$\mathbb{N}_+$						& Bezeichnet die Menge der Natürlichen Zahlen im Intervall $[0, \infty)$ \\
  			$\underline{p}$ 					& Punkt im Raum  \\
  			$\vec{v}$							& Vektor im Raum \\
  			$\langle\vec{a}, \vec{b}\rangle$ 	& Skalarprodukt der Vektoren $\vec{a}$ und $\vec{b}$ \\
 		\end{tabularx}
 		\caption{Verwendete Formelzeichen}
      	\label{tbl:Formelzeichen}
      	% Verweis im Text mittels \ref{tbl:beispieltabelle}
    \end{table}

%\section{Lokale und Globale Beleuchtung}
	
\section{Rendertechniken}

\subsection{Raytracing}

	Raytracing ist ein verfahren, bei dem Ausgehend von der Lichtquelle, oder der Bildebene Strahlen in
	die Szene geschickt werden. 
	Strahlen, die auf ein ein Objekt treffen werden reflektiert, gestreut oder gebrochen. 
	Die Möglichkeiten hängen vom Verwendeten Modell der Oberfläche und des Lichtes ab.
	Nach der Wechselwirkung mit der Oberfläche können weitere Strahlen durch die Szene verfolgt werden.
	Dieser Vorgang wir meist Rekursiv aufgebaut und nach dem erreichen einer entsprechenden Rekursionstiefe
	wird dieser abgebrochen.
	Das Bild selbst entsteht durch die Aufakkumulierung der Lichtintensitäten, welche die Bildebene erreichen.
	Modell dieser Technik ist die Strahlenoptik, welche das Licht auf Strahlen reduziert die durch die Szene
	geschossen werden. Beugungsphänomene werden bei dieser Technik vernachlässigt.
 
\subsection{Path und Lighttracer}

\subsubsection{Lighttracer}

	Der Lighttracer ist eine Spezialisierung des Raytracers, bei dem die Wege des Lichtes grundlegend,
	ausgehend von der Lichtquelle berechnet werden. Hierbei werden die Strahlen bis zum erreichen eines
	Abbruchkriteriums durch die Szene verfolgt und anschließend mit der Bildebene verbunden.
	
\subsubsection{Pathtracer}

	Auch der Pathtracer stellt eine Spezialisierung des Raytracers da, bei dem die Lichtwege zum einem
	ausgehend von der Bildebene und gleichzeitig ausgehend von der Lichtquelle betrachtet werden.
	Nach erreichen des Abbruchkriteriums werden die Lichtwege ausgehend von der Lichtquelle und der
	Bildebene mit einander Kombiniert. Durch dieses Vorgehen ergeben sich wesentlich schnell mehr mögliche
	Lichtwege, als beim normalen Rayztracingalgorithmus.
	Der Pathtracer ist ein State-Of-the-Art Algorithmus zur Berrechnung der Globalen Beleuchtung.
	
\subsection{Raycasting}

	Raycasting stellt eine Vereinfachte Form des Raytracing da, bei dieser Technik wird die Berrechnung der
	Beleuchtung bereits nach der ersten Kollision zwischen Strahl und Objekt abgebrochen.
	Raycasting ist die Grundlage des in dieser Arbeit verwendeten Renderalgorithmus.

\section{Strahl}
	Der Strahl ist das Zentrale Element jedes Raytracing Algorithmus. Seine Mathematische Beschreibung ist
	denkbar einfach:
	
	\begin{equation}
	  	\underline{r}(t) = \underline{p} + t \cdot \vec{r} \text{, mit } t \in \mathbb{R}_+
	  	\label{eq:Strahl}
	\end{equation}	
	
	Jeder Punkt auf dem Strahl, hier durch $\underline{r}$ bezeichnet, ergibt sich aus der Addition eines Stützpunktes $\underline{p}$
	mit dem Produkt eines Richtungsvektor $\vec{r}$ und einem skalaren Wert $t$. Durch das Produkt $t \cdot \vec{r}$ wird der
	Richtungsvektor $\vec{r}$ beliebig gestaucht oder gestreckt.

\section{Kugel}

	Eine Kugelfläche wird im $\mathbb{R}^3$ mit dem Mittelpunkt $\underline{m} = (x_0, y_0, z_0)$ und dem Radius $r$ durch folgende
	Formel parametrisiert.

	\begin{equation}
		(x - x_0)^2 + (y - y_0)^2 + (z - z_0)^2 = r^2
		\label{eq:KugelGleichung1}
	\end{equation}
	
	Jeder Punkt $\underline{p} = (x, y, z)$ der die Formel \ref{eq:KugelGleichung1} erfüllt liegt auf der Oberfläche der Kugel.
	Die Formel \ref{eq:KugelGleichung1} lässt sich auf beliebige $\mathbb{R}^n\text{, mit } n \in \mathbb{N}_+$ erweitern.
	
	\begin{equation}
		\langle\underline{p} - \underline{m}, \underline{p} - \underline{m}\rangle = r^2
		\label{eq:KugelGleichung2}
	\end{equation}
	
	Durch diese Verallgemeinerung der Formel \ref{eq:KugelGleichung1} zur Formel \ref{eq:KugelGleichung2} ist die Beschreibung der
	Kugel jetzt unabhängig von der Dimension.

\section{Schnittpunktberechnung}

	Eine Kugel ist definiert durch ihren Mittelpunkt $\underline{m}$ und ihren Radius $r$. Wird der Mittelpunkt der Kugel auf
	den Koordinaten Ursprung verschoben, liegen alle Punkte $p$ auf der Oberfläche $O$, wenn sie denn Abstand $r$ zum Koordinatenursprung haben. Die zu erfüllende Bedingung hat demnach folgende Form:
	
	\begin{equation}
		\vert\vert\underline{p}\vert\vert = r
		\label{eq:KugelGleichungBedingun1}
	\end{equation}
	
	Die Bedingung aus Formel \ref{eq:KugelGleichungBedingun1} lässt sich Quartieren wodurch sich die folgende Kugelgleichung ergibt:
	
	\begin{equation}
		\langle\underline{p}, \underline{p}\rangle = r^2
		\label{eq:Schnittpunktberechnung1}
	\end{equation}
	
	Um den Schnittpunkt der Kugel mit dem Strahl aus der Formel \ref{eq:Strahl} zu Berechnen, wird der Strahl in die Gleichung \ref{eq:Schnittpunktberechnung1} eingesetzt und erhält die folgende Gleichung:
	
	\begin{equation}
		r^2 = \langle\underline{p}, \underline{p}\rangle = \langle r(t), r(t) \rangle
		\label{eq:Schnittpunktberechnung2}
	\end{equation}
	
	diese Gleichung gilt es umzustellen und nach $t$ aufzulösen:
	
	\begin{equation}
		r^2 = \langle r(t), r(t) \rangle = \langle \underline{p} + t \cdot \vec{r}, \underline{p} + t \cdot \vec{r} \rangle
		\label{eq:Schnittpunktberechnung3}
	\end{equation}
	
	\begin{equation}
		r^2 = \langle \underline{p}, \underline{p}\rangle + 2 \cdot \langle \underline{p}, \vec{r} \rangle \cdot t + \langle \vec{r}, \vec{r} \rangle \cdot t^2
		\label{eq:Schnittpunktberechnung4}
	\end{equation}
	
	Die Formel \ref{eq:Schnittpunktberechnung4} entspricht einer allgemeinen Quadratischen Gleichung:
	
	\begin{equation}
		a \cdot x^2 + b \cdot x + c = 0 \text{, mit } a \neq 0
		\label{eq:AllgemeineQuadratischeGleichung}
	\end{equation}
	
	Für die allgemeine Quadratische Gleichung lassen sich die Nullstellen folgendermaßen bestimmen:
	
	\begin{equation}
		x_{1,2} = \frac{-b \pm \sqrt{b^2 - 4 \cdot a \cdot c}}{2 \cdot a}
		\label{eq:AllgemeineQuadratischeGleichungLösungsFormel}	
	\end{equation}
	
	Wird die Gleichung \ref{eq:Schnittpunktberechnung4} mithilfe der Allgemeinen Lösungsformel \ref{eq:AllgemeineQuadratischeGleichungLösungsFormel} für Quadratische Gleichungen nach $t$ aufgelöst, ergeben sich für
	$t$ zwei Lösungen $t_1$ und $t_2$:
	
	\begin{equation}
		t_{1,2} = \frac{-2 \cdot \langle \underline{p}, \vec{r} \rangle \pm \sqrt{4 \cdot \langle \underline{p}, \vec{r} \rangle^2 - 4 \cdot \langle \underline{p}, \underline{p} \rangle \cdot \langle \vec{r}, \vec{r} \rangle}}{2 \cdot \langle \vec{r}, \vec{r} \rangle}
		\label{eq:Schnittpunktberechnung5}
	\end{equation}
	
	Die Diskriminante $D$ wird der Teil der Formel bezeichnet der im Zähler der Gleichung \ref{eq:Schnittpunktberechnung5} unter der
	Wurzel steht.
	
	\begin{equation}
		D = 4 \cdot \langle \underline{p}, \vec{r} \rangle^2 - 4 \cdot \langle \underline{p}, \underline{p} \rangle \cdot \langle \vec{r}, \vec{r} \rangle
		\label{eq:Diskriminante}
	\end{equation}
	
	Mit Hilfe der  Diskriminante $D$ lässt sich eine Aussage über die Schnittpunkte zwischen Strahl und Kugel formulieren. 
	Wenn gilt, dass $D < 0$, dann gibt es keine Lösung im Zahlenbereich $\mathbb{R}$, das heißt der Strahl schneidet die Kugel nicht.
	Gilt, dass $D = 0$ ist, dann trifft der Strahl die Kugel an genau einer Stelle und die beiden Lösungen $t_1$ und $t_2$ haben
	identische Werte. Wenn aber gilt, dass $D > 0$, dann ergeben sich genau zwei Schnittpunkte an den Stellen $t_1$ und $t_2$.
	Um die Punkte zu bestimmen, an dem der Strahl die Kugel trifft setzt man $t_1$ und $t_2$ einfach in die Gleichung \ref{eq:Strahl} ein.

\section{Die Perspektivische Kamera}

	Die für den einfachen Raycaster nötigen Gleichungen sind in den Obigen Teil bereits hergeleitet. Was jetzt noch benötigt wird
	ist eine Beschreibung für die Bildebene. Ausgehend von der Bildebene werden die Licht stahlen in die Szene geschossen.
	Anders als bei einem Rasterizer wird keine Kamera und keine Projektionsmatrix benötigt. Die Kamera konstruiert sich gerade heraus.
	Zu Beginn wird eine sehr einfache Kamera betrachtet, welche nicht rotiert und nicht verschoben wird.
	
	Das bedeutet, das es sich bei der Kamera um eine Ebene $E$ handelt welche mit der Folgenden Gleichung beschrieben wird:
	
	\begin{equation}
		E(u, v) = \underline{p} + u \cdot \vec{p}_0 + v \cdot \vec{p}_1 \text{, mit } u \in [-1, 1] \text{ und } v \in [-1, 1]
		\label{eq:KameraEbene}	
	\end{equation}
	
	Da unsere Kamera am Koordinaten Ursprung Positioniert werden soll, kann der Punkt $\underline{p}$ vorerst vernachlässigt werden.
	Die Spannvektoren $\vec{p}_0$ und $\vec{p}_1$ sind folgender maßen definiert:
	
	\begin{equation}
		\vec{p}_0 = \left(\begin{array}{c} 1 \\ 0 \\ 0 \end{array}\right) \text{, }
		\vec{p}_1 = \left(\begin{array}{c} 0 \\ 1 \\ 0 \end{array}\right)
		\label{eq:KameraSpannvektoren}	
	\end{equation}
	
	Die Auf diese Weise beschriebe Ebene wird in Pixel unterteilt. Dadurch definiert sich jeder Pixel, als Teilfläche der Kameraebene.
	Die Eckpunkte jedes Pixels lässt sich durch zwei Wertepaare genau beschreiben.
	
\section{Die Orthogonale Kamera}

\chapter{Das Programm}

\section{Verdeckung}

Die endgültige Lichtintensität, die das Auge erreicht setzt sich zusammen aus:
 
$I = I_E + I_B + I_L$

dem emittierten Licht:

$I_E = \int\limits_{t_n}^{t_f} \tau(t_n, t) \cdot c(v_r(t)) dt $

dem ambienten Licht:

$I_B = \tau(t_n, t_f) \cdot I_b$

$\tau(t_0, t_1) = e^{- \int\limits_{t_0}^{t_1} \sigma (v_r(t)) dt}$

und dem Licht der Einzelnen Lichtquellen. Hier reduziert auf einen einzelnen Strahl der den Sichtstrahl $\underline{r}(t) = \underline{e} + t \cdot \vec{v}$ im Volumen schneidet. (An der Stelle t)

$I_L(t) = \tau(t_n, t) \cdot I_p(t)$

$I_p(t) = e^{- \int\limits_{0}^{l(t)} \cdot  \sigma (v_r(s)) ds} \cdot I_p$

$I_p(t) = e^{- \int\limits_{0}^{l(t)} \cdot  \lambda \cdot v_r(s) ds} \cdot I_p$

$I_p(t) = e^{- \int\limits_{0}^{l(t)} \cdot  \lambda \cdot \kappa ds} \cdot I_p$

$I_p(t) = e^{- \int\limits_{0}^{l(t)} \cdot  \lambda \cdot \kappa ds} \cdot I_p$

$I_p(t) = e^{- \lambda \cdot \kappa \cdot \int\limits_{0}^{l(t)} ds} \cdot I_p$

$I_p(t) = e^{- \lambda \cdot \kappa \cdot s} \cdot I_p$

$I_p(t) = e^{- \lambda \cdot \kappa \cdot \frac{-<p(t), d(t)>}{<d(t), d(t)>} + \frac{\sqrt{<p(t), d(t)>^2 - <p(t), p(t)> \cdot <d(t), d(t)>}}{<d(t), d(t)>}} \cdot I_p$

mit $d(t) = d$ da es sich um eine Richtungslichtquelle handelt

$I_p(t) = e^{- \lambda \cdot \kappa \cdot \frac{-<p(t), d>}{<d, d>} + \frac{\sqrt{<p(t), d>^2 - <p(t), p(t)> \cdot <d, d>}}{<d, d>}} \cdot I_p$

$I_{L(t)} = \tau(t_n, t) \cdot e^{- \lambda \cdot \kappa \cdot \frac{-<p(t), d>}{<d, d>} + \frac{\sqrt{<p(t), d>^2 - <p(t), p(t)> \cdot <d, d>}}{<d, d>}} \cdot I_p$

Daraus ergibt sich $I_L$ für eine Richtungslichtquelle

$I_L = \int\limits_{t_n}^{t_f} I_{L(t)} dt $

$I_L = \int\limits_{t_n}^{t_f} \tau(t_n, t) \cdot I_{p(t)} dt$

$I_L = \int\limits_{t_n}^{t_f} \tau(t_n, t) \cdot e^{- \lambda \cdot \kappa \cdot \frac{-<p(t), d>}{<d, d>} + \frac{\sqrt{<p(t), d>^2 - <p(t), p(t)> \cdot <d, d>}}{<d, d>}} \cdot I_p dt$


\chapter{Evaluation}

\chapter{Fazit}

%\chapter{title}
%
%\chapter{ein kapitel}
%\section{eine Grafik}
%\begin{figure}[htbp]
%	\centering
%		\includegraphics{test.png}
%	\caption{beschriftung}
%	\label{fig:diplominf}
%\end{figure}


%\subsection{Etwas Mathe}
%
%\[
%\sum_{i=1}^{100}x_i
%\]
%noch mehr text
%\subsubsection{Verweise auf Literatur}
%So kann ich Literatur aus literatur.bib zitieren: \cite{kochbuch}. 
%
%\paragraph{etwas quelltext}
%
%
%\begin{figure}[htbp]
%\begin{lstlisting}[frame=trbl]
%//comment
%for(int i = 0; i < 100;i++)
%{
%test(i);
%}
%\end{lstlisting}
%\end{figure}
%
%text
%
%\cite*{}

\end{document}